{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Microsoft Corporation.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import ollama\n",
    "from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    read_indexer_covariates,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_relationships,\n",
    "    read_indexer_reports,\n",
    "    read_indexer_text_units,\n",
    ")\n",
    "from graphrag.query.input.loaders.dfs import (\n",
    "    store_entity_semantic_embeddings,\n",
    ")\n",
    "# from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "# from graphrag.query.llm.oai.embedding import OpenAIEmbedding\n",
    "# from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.question_gen.local_gen import LocalQuestionGen\n",
    "from graphrag.query.structured_search.local_search.mixed_context import (\n",
    "    LocalSearchMixedContext,\n",
    ")\n",
    "from graphrag.query.structured_search.local_search.search import LocalSearch\n",
    "from graphrag.vector_stores.lancedb import LanceDBVectorStore\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Search Example\n",
    "\n",
    "Local search method generates answers by combining relevant data from the AI-extracted knowledge-graph with text chunks of the raw documents. This method is suitable for questions that require an understanding of specific entities mentioned in the documents (e.g. What are the healing properties of chamomile?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text units and graph data tables as context for local search\n",
    "\n",
    "- In this test we first load indexing outputs from parquet files to dataframes, then convert these dataframes into collections of data objects aligning with the knowledge model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tables to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"/Users/luwi/Documents/Code/microsoft_graphrag_local/ragdir_2/output\"#\"./inputs/operation dulce\"\n",
    "LANCEDB_URI = f\"{INPUT_DIR}/lancedb\"\n",
    "\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "RELATIONSHIP_TABLE = \"create_final_relationships\"\n",
    "COVARIATE_TABLE = \"create_final_covariates\"\n",
    "TEXT_UNIT_TABLE = \"create_final_text_units\"\n",
    "COMMUNITY_LEVEL = 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entity count: 25\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>level</th>\n",
       "      <th>title</th>\n",
       "      <th>type</th>\n",
       "      <th>description</th>\n",
       "      <th>source_id</th>\n",
       "      <th>entity_type</th>\n",
       "      <th>community</th>\n",
       "      <th>degree</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>id</th>\n",
       "      <th>size</th>\n",
       "      <th>graph_embedding</th>\n",
       "      <th>top_level_node_id</th>\n",
       "      <th>x</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>A method of using a graph to answer questions ...</td>\n",
       "      <td>e1e4f0675d6bb822863a64b663629c0f</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>40740b36141645ae854cc406f7ff129f</td>\n",
       "      <td>5</td>\n",
       "      <td>None</td>\n",
       "      <td>40740b36141645ae854cc406f7ff129f</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>PRIVATE TEXT CORPORA</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>A collection of text that is not publicly avai...</td>\n",
       "      <td>e1e4f0675d6bb822863a64b663629c0f</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>d1645731adb44d0e9c5650efd43850fa</td>\n",
       "      <td>3</td>\n",
       "      <td>None</td>\n",
       "      <td>d1645731adb44d0e9c5650efd43850fa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>USER QUESTIONS</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>Questions asked by users to be answered by the...</td>\n",
       "      <td>e1e4f0675d6bb822863a64b663629c0f</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>8500b245327b4ad2ac7e34a08088ee81</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>8500b245327b4ad2ac7e34a08088ee81</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>GRAPH RAG</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>bfe1a0b28685e4194ffc64e6bef2501b,e1e4f0675d6bb...</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "      <td>3</td>\n",
       "      <td>46f5bfc902b54297928abdd085d020ff</td>\n",
       "      <td>9</td>\n",
       "      <td>None</td>\n",
       "      <td>46f5bfc902b54297928abdd085d020ff</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>TEXT DATA</td>\n",
       "      <td>EVENT</td>\n",
       "      <td>A dataset of text used for training and testin...</td>\n",
       "      <td>e1e4f0675d6bb822863a64b663629c0f</td>\n",
       "      <td>None</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>601f6dd35109403bb5c9a66fda35512e</td>\n",
       "      <td>2</td>\n",
       "      <td>None</td>\n",
       "      <td>601f6dd35109403bb5c9a66fda35512e</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   level                 title   type  \\\n",
       "0      0    QUESTION ANSWERING  EVENT   \n",
       "1      0  PRIVATE TEXT CORPORA  EVENT   \n",
       "2      0        USER QUESTIONS  EVENT   \n",
       "3      0             GRAPH RAG          \n",
       "4      0             TEXT DATA  EVENT   \n",
       "\n",
       "                                         description  \\\n",
       "0  A method of using a graph to answer questions ...   \n",
       "1  A collection of text that is not publicly avai...   \n",
       "2  Questions asked by users to be answered by the...   \n",
       "3                                                      \n",
       "4  A dataset of text used for training and testin...   \n",
       "\n",
       "                                           source_id entity_type community  \\\n",
       "0                   e1e4f0675d6bb822863a64b663629c0f       EVENT         1   \n",
       "1                   e1e4f0675d6bb822863a64b663629c0f       EVENT         0   \n",
       "2                   e1e4f0675d6bb822863a64b663629c0f       EVENT         0   \n",
       "3  bfe1a0b28685e4194ffc64e6bef2501b,e1e4f0675d6bb...        None         1   \n",
       "4                   e1e4f0675d6bb822863a64b663629c0f        None         1   \n",
       "\n",
       "   degree  human_readable_id                                id  size  \\\n",
       "0       5                  0  40740b36141645ae854cc406f7ff129f     5   \n",
       "1       3                  1  d1645731adb44d0e9c5650efd43850fa     3   \n",
       "2       2                  2  8500b245327b4ad2ac7e34a08088ee81     2   \n",
       "3       9                  3  46f5bfc902b54297928abdd085d020ff     9   \n",
       "4       2                  4  601f6dd35109403bb5c9a66fda35512e     2   \n",
       "\n",
       "  graph_embedding                 top_level_node_id  x  y  \n",
       "0            None  40740b36141645ae854cc406f7ff129f  0  0  \n",
       "1            None  d1645731adb44d0e9c5650efd43850fa  0  0  \n",
       "2            None  8500b245327b4ad2ac7e34a08088ee81  0  0  \n",
       "3            None  46f5bfc902b54297928abdd085d020ff  0  0  \n",
       "4            None  601f6dd35109403bb5c9a66fda35512e  0  0  "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read nodes table to get community and degree data\n",
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "entity_embedding_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "\n",
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
    "\n",
    "# load description embeddings to an in-memory lancedb vectorstore\n",
    "# to connect to a remote db, specify url and port values.\n",
    "description_embedding_store = LanceDBVectorStore(\n",
    "    collection_name=\"entity_description_embeddings\",\n",
    ")\n",
    "description_embedding_store.connect(db_uri=LANCEDB_URI)\n",
    "entity_description_embeddings = store_entity_semantic_embeddings(\n",
    "    entities=entities, vectorstore=description_embedding_store\n",
    ")\n",
    "\n",
    "print(f\"Entity count: {len(entity_df)}\")\n",
    "entity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship count: 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "      <th>description</th>\n",
       "      <th>text_unit_ids</th>\n",
       "      <th>id</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>source_degree</th>\n",
       "      <th>target_degree</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>GRAPH RAG</td>\n",
       "      <td>16.0</td>\n",
       "      <td>The Graph RAG approach uses question answering...</td>\n",
       "      <td>[e1e4f0675d6bb822863a64b663629c0f]</td>\n",
       "      <td>3db243c5a3b9469687d7b3e6beebfdd4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>PRIVATE TEXT CORPORA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Question answering is used to index private te...</td>\n",
       "      <td>[e1e4f0675d6bb822863a64b663629c0f]</td>\n",
       "      <td>79dcf8d8b7ce4d17a80db0f448cc97d0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>TEXT DATA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Question answering models are trained on a lar...</td>\n",
       "      <td>[e1e4f0675d6bb822863a64b663629c0f]</td>\n",
       "      <td>32f3ebbf64c74a7baa1cfd1eb4ccd95a</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>MODEL TRAINING</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Question answering models are trained using th...</td>\n",
       "      <td>[e1e4f0675d6bb822863a64b663629c0f]</td>\n",
       "      <td>949ca6e4e6e94bf3980b26832735b233</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>EVALUATION METRICS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Question answering models are evaluated using ...</td>\n",
       "      <td>[e1e4f0675d6bb822863a64b663629c0f]</td>\n",
       "      <td>06a15aca87bf4691a0540036abef4ec0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               source                target  weight  \\\n",
       "0  QUESTION ANSWERING             GRAPH RAG    16.0   \n",
       "1  QUESTION ANSWERING  PRIVATE TEXT CORPORA     4.0   \n",
       "2  QUESTION ANSWERING             TEXT DATA     3.0   \n",
       "3  QUESTION ANSWERING        MODEL TRAINING     2.0   \n",
       "4  QUESTION ANSWERING    EVALUATION METRICS     2.0   \n",
       "\n",
       "                                         description  \\\n",
       "0  The Graph RAG approach uses question answering...   \n",
       "1  Question answering is used to index private te...   \n",
       "2  Question answering models are trained on a lar...   \n",
       "3  Question answering models are trained using th...   \n",
       "4  Question answering models are evaluated using ...   \n",
       "\n",
       "                        text_unit_ids                                id  \\\n",
       "0  [e1e4f0675d6bb822863a64b663629c0f]  3db243c5a3b9469687d7b3e6beebfdd4   \n",
       "1  [e1e4f0675d6bb822863a64b663629c0f]  79dcf8d8b7ce4d17a80db0f448cc97d0   \n",
       "2  [e1e4f0675d6bb822863a64b663629c0f]  32f3ebbf64c74a7baa1cfd1eb4ccd95a   \n",
       "3  [e1e4f0675d6bb822863a64b663629c0f]  949ca6e4e6e94bf3980b26832735b233   \n",
       "4  [e1e4f0675d6bb822863a64b663629c0f]  06a15aca87bf4691a0540036abef4ec0   \n",
       "\n",
       "  human_readable_id  source_degree  target_degree  rank  \n",
       "0                 0              5              9    14  \n",
       "1                 1              5              3     8  \n",
       "2                 2              5              2     7  \n",
       "3                 3              5              2     7  \n",
       "4                 4              5              2     7  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship_df = pd.read_parquet(f\"{INPUT_DIR}/{RELATIONSHIP_TABLE}.parquet\")\n",
    "relationships = read_indexer_relationships(relationship_df)\n",
    "\n",
    "print(f\"Relationship count: {len(relationship_df)}\")\n",
    "relationship_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: covariates are turned off by default, because they generally need prompt tuning to be valuable\n",
    "# Please see the GRAPHRAG_CLAIM_* settings\n",
    "\n",
    "# covariate_df = pd.read_parquet(f\"{INPUT_DIR}/{COVARIATE_TABLE}.parquet\")\n",
    "\n",
    "# claims = read_indexer_covariates(covariate_df)\n",
    "\n",
    "# print(f\"Claim records: {len(claims)}\")\n",
    "# covariates = {\"claims\": claims}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read community reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report records: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community</th>\n",
       "      <th>full_content</th>\n",
       "      <th>level</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>rank_explanation</th>\n",
       "      <th>summary</th>\n",
       "      <th>findings</th>\n",
       "      <th>full_content_json</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td># Private Text Corpora Community\\n\\nThis commu...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Private Text Corpora Community</td>\n",
       "      <td>The impact severity rating is moderate due to ...</td>\n",
       "      <td>This community revolves around a collection of...</td>\n",
       "      <td>[{'explanation': 'The Graph RAG approach is be...</td>\n",
       "      <td>{\\n    \"title\": \"Private Text Corpora Communit...</td>\n",
       "      <td>b054475a-a026-4260-9d93-6abf954a123d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td># Graph RAG Community\\n\\nThe Graph RAG communi...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Graph RAG Community</td>\n",
       "      <td>The Graph RAG community has a moderate impact ...</td>\n",
       "      <td>The Graph RAG community revolves around a grap...</td>\n",
       "      <td>[{'explanation': 'The Graph RAG community cent...</td>\n",
       "      <td>{\\n    \"title\": \"Graph RAG Community\",\\n    \"s...</td>\n",
       "      <td>cc10104e-5ecc-4e6a-a027-7acd2448a9d9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  community                                       full_content  level  rank  \\\n",
       "0         0  # Private Text Corpora Community\\n\\nThis commu...      0   6.0   \n",
       "1         1  # Graph RAG Community\\n\\nThe Graph RAG communi...      0   8.0   \n",
       "\n",
       "                            title  \\\n",
       "0  Private Text Corpora Community   \n",
       "1             Graph RAG Community   \n",
       "\n",
       "                                    rank_explanation  \\\n",
       "0  The impact severity rating is moderate due to ...   \n",
       "1  The Graph RAG community has a moderate impact ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  This community revolves around a collection of...   \n",
       "1  The Graph RAG community revolves around a grap...   \n",
       "\n",
       "                                            findings  \\\n",
       "0  [{'explanation': 'The Graph RAG approach is be...   \n",
       "1  [{'explanation': 'The Graph RAG community cent...   \n",
       "\n",
       "                                   full_content_json  \\\n",
       "0  {\\n    \"title\": \"Private Text Corpora Communit...   \n",
       "1  {\\n    \"title\": \"Graph RAG Community\",\\n    \"s...   \n",
       "\n",
       "                                     id  \n",
       "0  b054475a-a026-4260-9d93-6abf954a123d  \n",
       "1  cc10104e-5ecc-4e6a-a027-7acd2448a9d9  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)\n",
    "\n",
    "print(f\"Report records: {len(report_df)}\")\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read text units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text unit records: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>document_ids</th>\n",
       "      <th>entity_ids</th>\n",
       "      <th>relationship_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1e4f0675d6bb822863a64b663629c0f</td>\n",
       "      <td>To combine the strengths of these contrasting ...</td>\n",
       "      <td>44</td>\n",
       "      <td>[1730bed2b2faeda8ee1e88c01ac584b3]</td>\n",
       "      <td>[40740b36141645ae854cc406f7ff129f, d1645731adb...</td>\n",
       "      <td>[3db243c5a3b9469687d7b3e6beebfdd4, 79dcf8d8b7c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04becef81fb7d21fbe198dfca4e4d159</td>\n",
       "      <td>For a class of global sensemaking questions ov...</td>\n",
       "      <td>46</td>\n",
       "      <td>[889e75d03fdb3c2c486219d8495678ee]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bfe1a0b28685e4194ffc64e6bef2501b</td>\n",
       "      <td>An open-source, Python-based implementation of...</td>\n",
       "      <td>26</td>\n",
       "      <td>[94463dbd2b03a19805bf94f0c8552c47]</td>\n",
       "      <td>[46f5bfc902b54297928abdd085d020ff, 9c7fba7797a...</td>\n",
       "      <td>[f026b8337e8544cf93dacebf9247d574, c6ac85dbd97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7bf2b315168e3ec08a740d7638621161</td>\n",
       "      <td>Given a question, each community summary is us...</td>\n",
       "      <td>30</td>\n",
       "      <td>[bec823c0460d762ebedd21cd46ec9d68]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e5e6856d12d6ed343185093279e7d9a0</td>\n",
       "      <td>Prior QFS methods, meanwhile, fail to scale to...</td>\n",
       "      <td>22</td>\n",
       "      <td>[ca922d8b1c0c462898eb677966f148fd]</td>\n",
       "      <td>[cc6c98e369bc420a9a31101e387f8927, 34e6a3da1ad...</td>\n",
       "      <td>[33f2b5da86154f098dbfb024ead2be02, 9eaa628eb25...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  e1e4f0675d6bb822863a64b663629c0f   \n",
       "1  04becef81fb7d21fbe198dfca4e4d159   \n",
       "2  bfe1a0b28685e4194ffc64e6bef2501b   \n",
       "3  7bf2b315168e3ec08a740d7638621161   \n",
       "4  e5e6856d12d6ed343185093279e7d9a0   \n",
       "\n",
       "                                                text  n_tokens  \\\n",
       "0  To combine the strengths of these contrasting ...        44   \n",
       "1  For a class of global sensemaking questions ov...        46   \n",
       "2  An open-source, Python-based implementation of...        26   \n",
       "3  Given a question, each community summary is us...        30   \n",
       "4  Prior QFS methods, meanwhile, fail to scale to...        22   \n",
       "\n",
       "                         document_ids  \\\n",
       "0  [1730bed2b2faeda8ee1e88c01ac584b3]   \n",
       "1  [889e75d03fdb3c2c486219d8495678ee]   \n",
       "2  [94463dbd2b03a19805bf94f0c8552c47]   \n",
       "3  [bec823c0460d762ebedd21cd46ec9d68]   \n",
       "4  [ca922d8b1c0c462898eb677966f148fd]   \n",
       "\n",
       "                                          entity_ids  \\\n",
       "0  [40740b36141645ae854cc406f7ff129f, d1645731adb...   \n",
       "1                                               None   \n",
       "2  [46f5bfc902b54297928abdd085d020ff, 9c7fba7797a...   \n",
       "3                                               None   \n",
       "4  [cc6c98e369bc420a9a31101e387f8927, 34e6a3da1ad...   \n",
       "\n",
       "                                    relationship_ids  \n",
       "0  [3db243c5a3b9469687d7b3e6beebfdd4, 79dcf8d8b7c...  \n",
       "1                                               None  \n",
       "2  [f026b8337e8544cf93dacebf9247d574, c6ac85dbd97...  \n",
       "3                                               None  \n",
       "4  [33f2b5da86154f098dbfb024ead2be02, 9eaa628eb25...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_unit_df = pd.read_parquet(f\"{INPUT_DIR}/{TEXT_UNIT_TABLE}.parquet\")\n",
    "text_units = read_indexer_text_units(text_unit_df)\n",
    "\n",
    "print(f\"Text unit records: {len(text_unit_df)}\")\n",
    "text_unit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_model = os.environ[\"GRAPHRAG_LLM_MODEL\"]\n",
    "# embedding_model = os.environ[\"GRAPHRAG_EMBEDDING_MODEL\"]\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=\"ollama\",\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    model=\"llama3.1\",\n",
    "    # callbacks=[callback_handler],\n",
    ")\n",
    "\n",
    "token_encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "class OpenAICompatibleOllamaEmbedding:\n",
    "    def __init__(self, model: str):\n",
    "        self.model = model\n",
    "\n",
    "    def __call__(self, prompt: str):\n",
    "        return ollama.embeddings(model=self.model, prompt=prompt)[\"embedding\"]\n",
    "\n",
    "    def embed(self, prompt: str):\n",
    "        return self(prompt=prompt)\n",
    "    \n",
    "    def embed_documents(self, texts: list[str]):\n",
    "        return [self(text) for text in texts]\n",
    "\n",
    "text_embedder = OpenAICompatibleOllamaEmbedding(model=\"nomic-embed-text\")\n",
    "\n",
    "# text_embedder = OpenAIEmbedding(\n",
    "#     api_key=api_key,\n",
    "#     api_base=None,\n",
    "#     api_type=OpenaiApiType.OpenAI,\n",
    "#     model=embedding_model,\n",
    "#     deployment_name=embedding_model,\n",
    "#     max_retries=20,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create local search context builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder = LocalSearchMixedContext(\n",
    "    community_reports=reports,\n",
    "    text_units=text_units,\n",
    "    entities=entities,\n",
    "    relationships=relationships,\n",
    "    # if you did not run covariates during indexing, set this to None\n",
    "    # covariates=covariates,\n",
    "    entity_text_embeddings=description_embedding_store,\n",
    "    embedding_vectorstore_key=EntityVectorStoreKey.ID,  # if the vectorstore uses entity title as ids, set this to EntityVectorStoreKey.TITLE\n",
    "    text_embedder=text_embedder,\n",
    "    token_encoder=token_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create local search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_unit_prop: proportion of context window dedicated to related text units\n",
    "# community_prop: proportion of context window dedicated to community reports.\n",
    "# The remaining proportion is dedicated to entities and relationships. Sum of text_unit_prop and community_prop should be <= 1\n",
    "# conversation_history_max_turns: maximum number of turns to include in the conversation history.\n",
    "# conversation_history_user_turns_only: if True, only include user queries in the conversation history.\n",
    "# top_k_mapped_entities: number of related entities to retrieve from the entity description embedding store.\n",
    "# top_k_relationships: control the number of out-of-network relationships to pull into the context window.\n",
    "# include_entity_rank: if True, include the entity rank in the entity table in the context window. Default entity rank = node degree.\n",
    "# include_relationship_weight: if True, include the relationship weight in the context window.\n",
    "# include_community_rank: if True, include the community rank in the context window.\n",
    "# return_candidate_context: if True, return a set of dataframes containing all candidate entity/relationship/covariate records that\n",
    "# could be relevant. Note that not all of these records will be included in the context window. The \"in_context\" column in these\n",
    "# dataframes indicates whether the record is included in the context window.\n",
    "# max_tokens: maximum number of tokens to use for the context window.\n",
    "\n",
    "\n",
    "local_context_params = {\n",
    "    \"text_unit_prop\": 0.5,\n",
    "    \"community_prop\": 0.1,\n",
    "    \"conversation_history_max_turns\": 5,\n",
    "    \"conversation_history_user_turns_only\": True,\n",
    "    \"top_k_mapped_entities\": 10,\n",
    "    \"top_k_relationships\": 10,\n",
    "    \"include_entity_rank\": True,\n",
    "    \"include_relationship_weight\": True,\n",
    "    \"include_community_rank\": False,\n",
    "    \"return_candidate_context\": False,\n",
    "    \"embedding_vectorstore_key\": EntityVectorStoreKey.ID,  # set this to EntityVectorStoreKey.TITLE if the vectorstore uses entity title as ids\n",
    "    \"max_tokens\": 12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "}\n",
    "\n",
    "llm_params = {\n",
    "    \"max_tokens\": 2_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 1000=1500)\n",
    "    \"temperature\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = LocalSearch(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    llm_params=llm_params,\n",
    "    context_builder_params=local_context_params,\n",
    "    response_type=\"multiple paragraphs\",  # free form text describing the response type and format, can be anything, e.g. prioritized list, single paragraph, multiple paragraphs, multiple-page report\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run local search on sample queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages {'role': 'system', 'content': '\\n---Role---\\n\\nYou are a helpful assistant responding to questions about data in the tables provided.\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\n\\n---Data tables---\\n\\n-----Reports-----\\nid|title|content\\n1|Graph RAG Community|\"# Graph RAG Community\\n\\nThe Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\\n\\n## Graph RAG is a graph-based approach to question answering\\n\\nThe Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\\n\\n## Model training is a crucial aspect of the Graph RAG community\\n\\nModel training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Evaluation metrics are essential for assessing the performance of question answering models\\n\\nThe Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\\n\\n## Graph RAG is implemented in Python\\n\\nThe Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Graph RAG has a strong focus on Microsoft\\n\\nThe Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company\\'s resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\\n\\n\\n-----Entities-----\\nid|entity|description|number of relationships\\n4|TEXT DATA|A dataset of text used for training and testing question answering models|2\\n17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\\n5|MODEL TRAINING|A process of training machine learning models on a dataset|2\\n0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\\n21|TEXT PROCESSING|The process of extracting information from text documents|1\\n2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\\n18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\\n15|INDEXING||1\\n19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\\n7|HTTPS://AKA.MS/GRAPHRAG||1\\n13|METHODS||1\\n24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\\n8|MS|Microsoft is the company behind the Graph RAG implementation|1\\n1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\\n23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\\n20|LLM||5\\n6|EVALUATION METRICS|A set of metrics used to evaluate the performance of question answering models|2\\n12|TEXT||1\\n16|SEARCHING||1\\n14|SYSTEMS||1\\n\\n\\n-----Relationships-----\\nid|source|target|description|weight|rank|links\\n1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|2\\n23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|4\\n2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|2\\n3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|2\\n4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|1\\n20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|4\\n26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|4\\n27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|4\\n6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|2\\n22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|2\\n21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|2\\n24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\\n0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|8\\n5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|8\\n7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|8\\n8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|8\\n9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|8\\n10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|8\\n11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|8\\n13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|8\\n17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|3\\n18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|3\\n19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|3\\n15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|2\\n16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|2\\n25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|1\\n\\n\\n-----Sources-----\\nid|text\\n0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\\n6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\\n4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\\n2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\\n\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\nAdd sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\\n'}\n",
      "input \n",
      "---Role---\n",
      "\n",
      "You are a helpful assistant responding to questions about data in the tables provided.\n",
      "\n",
      "\n",
      "---Goal---\n",
      "\n",
      "Generate a response of the target length and format that responds to the user's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\n",
      "\n",
      "If you don't know the answer, just say so. Do not make anything up.\n",
      "\n",
      "Points supported by data should list their data references as follows:\n",
      "\n",
      "\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\n",
      "\n",
      "Do not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
      "\n",
      "For example:\n",
      "\n",
      "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\n",
      "\n",
      "where 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n",
      "\n",
      "Do not include information where the supporting evidence for it is not provided.\n",
      "\n",
      "\n",
      "---Target response length and format---\n",
      "\n",
      "multiple paragraphs\n",
      "\n",
      "\n",
      "---Data tables---\n",
      "\n",
      "-----Reports-----\n",
      "id|title|content\n",
      "1|Graph RAG Community|\"# Graph RAG Community\n",
      "\n",
      "The Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\n",
      "\n",
      "## Graph RAG is a graph-based approach to question answering\n",
      "\n",
      "The Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\n",
      "\n",
      "## Model training is a crucial aspect of the Graph RAG community\n",
      "\n",
      "Model training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\n",
      "\n",
      "## Evaluation metrics are essential for assessing the performance of question answering models\n",
      "\n",
      "The Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\n",
      "\n",
      "## Graph RAG is implemented in Python\n",
      "\n",
      "The Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\n",
      "\n",
      "## Graph RAG has a strong focus on Microsoft\n",
      "\n",
      "The Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company's resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\n",
      "\n",
      "\n",
      "-----Entities-----\n",
      "id|entity|description|number of relationships\n",
      "4|TEXT DATA|A dataset of text used for training and testing question answering models|2\n",
      "17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\n",
      "5|MODEL TRAINING|A process of training machine learning models on a dataset|2\n",
      "0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\n",
      "21|TEXT PROCESSING|The process of extracting information from text documents|1\n",
      "2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\n",
      "18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\n",
      "15|INDEXING||1\n",
      "19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\n",
      "7|HTTPS://AKA.MS/GRAPHRAG||1\n",
      "13|METHODS||1\n",
      "24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\n",
      "8|MS|Microsoft is the company behind the Graph RAG implementation|1\n",
      "1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\n",
      "23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\n",
      "20|LLM||5\n",
      "6|EVALUATION METRICS|A set of metrics used to evaluate the performance of question answering models|2\n",
      "12|TEXT||1\n",
      "16|SEARCHING||1\n",
      "14|SYSTEMS||1\n",
      "\n",
      "\n",
      "-----Relationships-----\n",
      "id|source|target|description|weight|rank|links\n",
      "1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|2\n",
      "23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|4\n",
      "2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|2\n",
      "3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|2\n",
      "4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|1\n",
      "20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|4\n",
      "26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|4\n",
      "27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|4\n",
      "6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|2\n",
      "22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|2\n",
      "21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|2\n",
      "24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\n",
      "0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|8\n",
      "5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|8\n",
      "7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|8\n",
      "8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|8\n",
      "9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|8\n",
      "10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|8\n",
      "11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|8\n",
      "13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|8\n",
      "17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|3\n",
      "18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|3\n",
      "19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|3\n",
      "15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|2\n",
      "16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|2\n",
      "25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|1\n",
      "\n",
      "\n",
      "-----Sources-----\n",
      "id|text\n",
      "0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\n",
      "6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\n",
      "4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\n",
      "2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\n",
      "\n",
      "\n",
      "\n",
      "---Goal---\n",
      "\n",
      "Generate a response of the target length and format that responds to the user's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\n",
      "\n",
      "If you don't know the answer, just say so. Do not make anything up.\n",
      "\n",
      "Points supported by data should list their data references as follows:\n",
      "\n",
      "\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\n",
      "\n",
      "Do not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
      "\n",
      "For example:\n",
      "\n",
      "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\n",
      "\n",
      "where 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n",
      "\n",
      "Do not include information where the supporting evidence for it is not provided.\n",
      "\n",
      "\n",
      "---Target response length and format---\n",
      "\n",
      "multiple paragraphs\n",
      "\n",
      "Add sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\n",
      "\n",
      "payload {'messages': [{'content': '\\n---Role---\\n\\nYou are a helpful assistant responding to questions about data in the tables provided.\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\n\\n---Data tables---\\n\\n-----Reports-----\\nid|title|content\\n1|Graph RAG Community|\"# Graph RAG Community\\n\\nThe Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\\n\\n## Graph RAG is a graph-based approach to question answering\\n\\nThe Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\\n\\n## Model training is a crucial aspect of the Graph RAG community\\n\\nModel training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Evaluation metrics are essential for assessing the performance of question answering models\\n\\nThe Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\\n\\n## Graph RAG is implemented in Python\\n\\nThe Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Graph RAG has a strong focus on Microsoft\\n\\nThe Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company\\'s resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\\n\\n\\n-----Entities-----\\nid|entity|description|number of relationships\\n4|TEXT DATA|A dataset of text used for training and testing question answering models|2\\n17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\\n5|MODEL TRAINING|A process of training machine learning models on a dataset|2\\n0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\\n21|TEXT PROCESSING|The process of extracting information from text documents|1\\n2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\\n18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\\n15|INDEXING||1\\n19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\\n7|HTTPS://AKA.MS/GRAPHRAG||1\\n13|METHODS||1\\n24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\\n8|MS|Microsoft is the company behind the Graph RAG implementation|1\\n1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\\n23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\\n20|LLM||5\\n6|EVALUATION METRICS|A set of metrics used to evaluate the performance of question answering models|2\\n12|TEXT||1\\n16|SEARCHING||1\\n14|SYSTEMS||1\\n\\n\\n-----Relationships-----\\nid|source|target|description|weight|rank|links\\n1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|2\\n23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|4\\n2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|2\\n3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|2\\n4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|1\\n20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|4\\n26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|4\\n27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|4\\n6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|2\\n22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|2\\n21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|2\\n24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\\n0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|8\\n5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|8\\n7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|8\\n8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|8\\n9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|8\\n10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|8\\n11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|8\\n13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|8\\n17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|3\\n18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|3\\n19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|3\\n15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|2\\n16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|2\\n25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|1\\n\\n\\n-----Sources-----\\nid|text\\n0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\\n6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\\n4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\\n2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\\n\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\nAdd sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\\n', 'role': 'user'}], 'model': 'llama3.1', 'stream': False, 'n': 1, 'temperature': 0.0, 'streaming': True, 'max_tokens': 2000}\n",
      "messages {'role': 'user', 'content': 'Tell me about Ishita Mann'}\n",
      "input Tell me about Ishita Mann\n",
      "payload {'messages': [{'content': 'Tell me about Ishita Mann', 'role': 'user'}], 'model': 'llama3.1', 'stream': False, 'n': 1, 'temperature': 0.0, 'streaming': True, 'max_tokens': 2000}\n",
      "generations=[[ChatGeneration(text='**Graph RAG Approach: A Scalable Solution for Question Answering over Private Text Corpora**\\n=====================================================================================\\n\\nThe Graph RAG approach is a novel method for answering user questions by indexing private text corpora, leveraging the strengths of both contrasting methods [0]. This approach scales with both the generality of user questions and the quantity of source text to be indexed [0].\\n\\n**Key Components of the Graph RAG Approach**\\n------------------------------------------\\n\\nThe Graph RAG approach involves two stages:\\n\\n1. **Entity Knowledge Graph**: An LLM is used to build a graph-based text index by deriving an entity knowledge graph from the source documents [25]. This stage enables the identification of closely-related entities.\\n2. **Community Summaries**: The graph-based text index is then used to pre-generate community summaries for all groups of closely-related entities [21, 22].\\n\\n**Advantages over Prior QFS Methods**\\n--------------------------------------\\n\\nPrior QFS methods fail to scale to the quantities of text indexed by typical RAG systems, making searching difficult [16]. In contrast, the Graph RAG approach is designed to handle large amounts of text and user questions.\\n\\n**Implementation and Availability**\\n-------------------------------\\n\\nAn open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag [2].\\n\\n**Conclusion**\\n----------\\n\\nThe Graph RAG approach offers a scalable solution for question answering over private text corpora. By leveraging the strengths of contrasting methods and addressing the limitations of prior QFS methods, this approach has the potential to revolutionize the way we answer user questions.\\n\\nNote: The above response is based on the provided data tables and does not include any information that is not supported by the evidence.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='**Graph RAG Approach: A Scalable Solution for Question Answering over Private Text Corpora**\\n=====================================================================================\\n\\nThe Graph RAG approach is a novel method for answering user questions by indexing private text corpora, leveraging the strengths of both contrasting methods [0]. This approach scales with both the generality of user questions and the quantity of source text to be indexed [0].\\n\\n**Key Components of the Graph RAG Approach**\\n------------------------------------------\\n\\nThe Graph RAG approach involves two stages:\\n\\n1. **Entity Knowledge Graph**: An LLM is used to build a graph-based text index by deriving an entity knowledge graph from the source documents [25]. This stage enables the identification of closely-related entities.\\n2. **Community Summaries**: The graph-based text index is then used to pre-generate community summaries for all groups of closely-related entities [21, 22].\\n\\n**Advantages over Prior QFS Methods**\\n--------------------------------------\\n\\nPrior QFS methods fail to scale to the quantities of text indexed by typical RAG systems, making searching difficult [16]. In contrast, the Graph RAG approach is designed to handle large amounts of text and user questions.\\n\\n**Implementation and Availability**\\n-------------------------------\\n\\nAn open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag [2].\\n\\n**Conclusion**\\n----------\\n\\nThe Graph RAG approach offers a scalable solution for question answering over private text corpora. By leveraging the strengths of contrasting methods and addressing the limitations of prior QFS methods, this approach has the potential to revolutionize the way we answer user questions.\\n\\nNote: The above response is based on the provided data tables and does not include any information that is not supported by the evidence.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 345, 'prompt_tokens': 1026, 'total_tokens': 1371, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-5df49672-0d8f-4b06-9295-e6945625e01a-0', usage_metadata={'input_tokens': 1026, 'output_tokens': 345, 'total_tokens': 1371}))], [ChatGeneration(text=\"I couldn't find any notable or well-known information on a person named Ishita Mann. It's possible that she is a private individual, not a public figure, or may not have a significant online presence.\\n\\nHowever, I can suggest some possibilities:\\n\\n1. **Indian name**: Ishita is a common Indian name, and there might be many people with this name in India.\\n2. **Local or regional significance**: Ishita Mann might be a notable person in her local community or region, but not well-known outside of it.\\n3. **Private individual**: As mentioned earlier, she could be a private individual who doesn't have an online presence or hasn't gained significant public attention.\\n\\nIf you could provide more context or information about Ishita Mann (e.g., profession, location, interests), I might be able to help you better!\", generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content=\"I couldn't find any notable or well-known information on a person named Ishita Mann. It's possible that she is a private individual, not a public figure, or may not have a significant online presence.\\n\\nHowever, I can suggest some possibilities:\\n\\n1. **Indian name**: Ishita is a common Indian name, and there might be many people with this name in India.\\n2. **Local or regional significance**: Ishita Mann might be a notable person in her local community or region, but not well-known outside of it.\\n3. **Private individual**: As mentioned earlier, she could be a private individual who doesn't have an online presence or hasn't gained significant public attention.\\n\\nIf you could provide more context or information about Ishita Mann (e.g., profession, location, interests), I might be able to help you better!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 170, 'prompt_tokens': 16, 'total_tokens': 186, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-e2e009c0-0f68-4d07-a7a7-bc355a973347-0', usage_metadata={'input_tokens': 16, 'output_tokens': 170, 'total_tokens': 186}))]] llm_output={'token_usage': {'completion_tokens': 515, 'prompt_tokens': 1042, 'total_tokens': 1557, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama'} run=[RunInfo(run_id=UUID('5df49672-0d8f-4b06-9295-e6945625e01a')), RunInfo(run_id=UUID('e2e009c0-0f68-4d07-a7a7-bc355a973347'))] type='LLMResult'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:357: UserWarning: Unexpected type for token usage: <class 'NoneType'>\n",
      "  warnings.warn(f\"Unexpected type for token usage: {type(new_usage)}\")\n"
     ]
    }
   ],
   "source": [
    "result = await search_engine.asearch(\"Tell me about Ishita Mann\")\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages {'role': 'system', 'content': '\\n---Role---\\n\\nYou are a helpful assistant responding to questions about data in the tables provided.\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\n\\n---Data tables---\\n\\n-----Reports-----\\nid|title|content\\n1|Graph RAG Community|\"# Graph RAG Community\\n\\nThe Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\\n\\n## Graph RAG is a graph-based approach to question answering\\n\\nThe Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\\n\\n## Model training is a crucial aspect of the Graph RAG community\\n\\nModel training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Evaluation metrics are essential for assessing the performance of question answering models\\n\\nThe Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\\n\\n## Graph RAG is implemented in Python\\n\\nThe Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Graph RAG has a strong focus on Microsoft\\n\\nThe Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company\\'s resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\\n\\n\\n-----Entities-----\\nid|entity|description|number of relationships\\n3|GRAPH RAG||9\\n2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\\n8|MS|Microsoft is the company behind the Graph RAG implementation|1\\n7|HTTPS://AKA.MS/GRAPHRAG||1\\n0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\\n17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\\n11|RAG SYSTEMS||4\\n18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\\n19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\\n22|ENTITY KNOWLEDGE GRAPH||1\\n4|TEXT DATA|A dataset of text used for training and testing question answering models|2\\n1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\\n15|INDEXING||1\\n13|METHODS||1\\n9|PYTHON||1\\n24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\\n12|TEXT||1\\n16|SEARCHING||1\\n23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\\n5|MODEL TRAINING|A process of training machine learning models on a dataset|2\\n\\n\\n-----Relationships-----\\nid|source|target|description|weight|rank|links\\n0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|1\\n5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|3\\n7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|1\\n8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|2\\n9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|2\\n11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|1\\n12|GRAPH RAG|PYTHON|Graph RAG is implemented in Python|8.0|10|1\\n13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|1\\n1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|3\\n2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|2\\n3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|2\\n6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|3\\n17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|1\\n19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|1\\n22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|2\\n21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|2\\n23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|5\\n20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|5\\n25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|5\\n26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|5\\n27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|5\\n14|QFS|RAG SYSTEMS|QFS methods fail to scale to the quantities of text indexed by typical RAG systems|3.0|7|3\\n15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|3\\n16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|3\\n10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|2\\n4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|2\\n18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|1\\n24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\\n\\n\\n-----Sources-----\\nid|text\\n0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\\n2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\\n6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\\n4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\\n\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\nAdd sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\\n'}\n",
      "input \n",
      "---Role---\n",
      "\n",
      "You are a helpful assistant responding to questions about data in the tables provided.\n",
      "\n",
      "\n",
      "---Goal---\n",
      "\n",
      "Generate a response of the target length and format that responds to the user's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\n",
      "\n",
      "If you don't know the answer, just say so. Do not make anything up.\n",
      "\n",
      "Points supported by data should list their data references as follows:\n",
      "\n",
      "\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\n",
      "\n",
      "Do not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
      "\n",
      "For example:\n",
      "\n",
      "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\n",
      "\n",
      "where 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n",
      "\n",
      "Do not include information where the supporting evidence for it is not provided.\n",
      "\n",
      "\n",
      "---Target response length and format---\n",
      "\n",
      "multiple paragraphs\n",
      "\n",
      "\n",
      "---Data tables---\n",
      "\n",
      "-----Reports-----\n",
      "id|title|content\n",
      "1|Graph RAG Community|\"# Graph RAG Community\n",
      "\n",
      "The Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\n",
      "\n",
      "## Graph RAG is a graph-based approach to question answering\n",
      "\n",
      "The Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\n",
      "\n",
      "## Model training is a crucial aspect of the Graph RAG community\n",
      "\n",
      "Model training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\n",
      "\n",
      "## Evaluation metrics are essential for assessing the performance of question answering models\n",
      "\n",
      "The Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\n",
      "\n",
      "## Graph RAG is implemented in Python\n",
      "\n",
      "The Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\n",
      "\n",
      "## Graph RAG has a strong focus on Microsoft\n",
      "\n",
      "The Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company's resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\n",
      "\n",
      "\n",
      "-----Entities-----\n",
      "id|entity|description|number of relationships\n",
      "3|GRAPH RAG||9\n",
      "2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\n",
      "8|MS|Microsoft is the company behind the Graph RAG implementation|1\n",
      "7|HTTPS://AKA.MS/GRAPHRAG||1\n",
      "0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\n",
      "17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\n",
      "11|RAG SYSTEMS||4\n",
      "18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\n",
      "19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\n",
      "22|ENTITY KNOWLEDGE GRAPH||1\n",
      "4|TEXT DATA|A dataset of text used for training and testing question answering models|2\n",
      "1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\n",
      "15|INDEXING||1\n",
      "13|METHODS||1\n",
      "9|PYTHON||1\n",
      "24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\n",
      "12|TEXT||1\n",
      "16|SEARCHING||1\n",
      "23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\n",
      "5|MODEL TRAINING|A process of training machine learning models on a dataset|2\n",
      "\n",
      "\n",
      "-----Relationships-----\n",
      "id|source|target|description|weight|rank|links\n",
      "0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|1\n",
      "5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|3\n",
      "7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|1\n",
      "8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|2\n",
      "9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|2\n",
      "11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|1\n",
      "12|GRAPH RAG|PYTHON|Graph RAG is implemented in Python|8.0|10|1\n",
      "13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|1\n",
      "1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|3\n",
      "2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|2\n",
      "3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|2\n",
      "6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|3\n",
      "17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|1\n",
      "19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|1\n",
      "22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|2\n",
      "21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|2\n",
      "23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|5\n",
      "20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|5\n",
      "25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|5\n",
      "26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|5\n",
      "27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|5\n",
      "14|QFS|RAG SYSTEMS|QFS methods fail to scale to the quantities of text indexed by typical RAG systems|3.0|7|3\n",
      "15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|3\n",
      "16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|3\n",
      "10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|2\n",
      "4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|2\n",
      "18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|1\n",
      "24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\n",
      "\n",
      "\n",
      "-----Sources-----\n",
      "id|text\n",
      "0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\n",
      "2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\n",
      "6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\n",
      "4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\n",
      "\n",
      "\n",
      "\n",
      "---Goal---\n",
      "\n",
      "Generate a response of the target length and format that responds to the user's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\n",
      "\n",
      "If you don't know the answer, just say so. Do not make anything up.\n",
      "\n",
      "Points supported by data should list their data references as follows:\n",
      "\n",
      "\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\n",
      "\n",
      "Do not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
      "\n",
      "For example:\n",
      "\n",
      "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\n",
      "\n",
      "where 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n",
      "\n",
      "Do not include information where the supporting evidence for it is not provided.\n",
      "\n",
      "\n",
      "---Target response length and format---\n",
      "\n",
      "multiple paragraphs\n",
      "\n",
      "Add sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\n",
      "\n",
      "payload {'messages': [{'content': '\\n---Role---\\n\\nYou are a helpful assistant responding to questions about data in the tables provided.\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\n\\n---Data tables---\\n\\n-----Reports-----\\nid|title|content\\n1|Graph RAG Community|\"# Graph RAG Community\\n\\nThe Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\\n\\n## Graph RAG is a graph-based approach to question answering\\n\\nThe Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\\n\\n## Model training is a crucial aspect of the Graph RAG community\\n\\nModel training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Evaluation metrics are essential for assessing the performance of question answering models\\n\\nThe Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\\n\\n## Graph RAG is implemented in Python\\n\\nThe Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Graph RAG has a strong focus on Microsoft\\n\\nThe Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company\\'s resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\\n\\n\\n-----Entities-----\\nid|entity|description|number of relationships\\n3|GRAPH RAG||9\\n2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\\n8|MS|Microsoft is the company behind the Graph RAG implementation|1\\n7|HTTPS://AKA.MS/GRAPHRAG||1\\n0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\\n17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\\n11|RAG SYSTEMS||4\\n18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\\n19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\\n22|ENTITY KNOWLEDGE GRAPH||1\\n4|TEXT DATA|A dataset of text used for training and testing question answering models|2\\n1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\\n15|INDEXING||1\\n13|METHODS||1\\n9|PYTHON||1\\n24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\\n12|TEXT||1\\n16|SEARCHING||1\\n23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\\n5|MODEL TRAINING|A process of training machine learning models on a dataset|2\\n\\n\\n-----Relationships-----\\nid|source|target|description|weight|rank|links\\n0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|1\\n5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|3\\n7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|1\\n8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|2\\n9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|2\\n11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|1\\n12|GRAPH RAG|PYTHON|Graph RAG is implemented in Python|8.0|10|1\\n13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|1\\n1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|3\\n2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|2\\n3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|2\\n6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|3\\n17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|1\\n19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|1\\n22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|2\\n21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|2\\n23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|5\\n20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|5\\n25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|5\\n26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|5\\n27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|5\\n14|QFS|RAG SYSTEMS|QFS methods fail to scale to the quantities of text indexed by typical RAG systems|3.0|7|3\\n15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|3\\n16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|3\\n10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|2\\n4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|2\\n18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|1\\n24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\\n\\n\\n-----Sources-----\\nid|text\\n0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\\n2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\\n6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\\n4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\\n\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\nAdd sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\\n', 'role': 'user'}], 'model': 'llama3.1', 'stream': False, 'n': 1, 'temperature': 0.0, 'streaming': True, 'max_tokens': 2000}\n",
      "messages {'role': 'user', 'content': 'what is the usecase of Graph RAG'}\n",
      "input what is the usecase of Graph RAG\n",
      "payload {'messages': [{'content': 'what is the usecase of Graph RAG', 'role': 'user'}], 'model': 'llama3.1', 'stream': False, 'n': 1, 'temperature': 0.0, 'streaming': True, 'max_tokens': 2000}\n",
      "generations=[[ChatGeneration(text='**Question Answering over Private Text Corpora: A Graph RAG Approach**\\n====================================================================\\n\\nThe Graph RAG approach is a novel method for indexing private text corpora using large language models (LLMs) [Data: 0, 6]. This approach scales with both the generality of user questions and the quantity of source text to be indexed, making it an attractive solution for question answering over large datasets.\\n\\n**Key Components of the Graph RAG Approach**\\n------------------------------------------\\n\\nThe Graph RAG approach involves two primary stages:\\n\\n1. **Entity Knowledge Graph Construction**: The LLM is used to derive an entity knowledge graph from the source documents [Data: 23]. This stage involves processing the source documents using various techniques, including text processing and analysis [Data: 24].\\n2. **Community Summaries Generation**: The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities [Data: 22, 21].\\n\\n**Advantages over Traditional QFS Methods**\\n------------------------------------------\\n\\nPrior methods for querying and searching large amounts of text (QFS) fail to scale to the quantities of text indexed by typical RAG systems [Data: 14, 15, 16]. In contrast, the Graph RAG approach is designed to handle large datasets and provide accurate question answering results.\\n\\n**Evaluation Metrics**\\n-------------------\\n\\nThe Graph RAG approach is evaluated using a set of evaluation metrics, including those used for question answering models [Data: 10, 4].\\n\\n**Conclusion**\\n----------\\n\\nIn conclusion, the Graph RAG approach offers a scalable solution for indexing private text corpora and providing accurate question answering results. By leveraging LLMs and graph-based indexing techniques, this approach can handle large datasets and provide valuable insights to users.\\n\\nNote: The above response is based on the provided data tables and does not include any information that is not supported by the evidence.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='**Question Answering over Private Text Corpora: A Graph RAG Approach**\\n====================================================================\\n\\nThe Graph RAG approach is a novel method for indexing private text corpora using large language models (LLMs) [Data: 0, 6]. This approach scales with both the generality of user questions and the quantity of source text to be indexed, making it an attractive solution for question answering over large datasets.\\n\\n**Key Components of the Graph RAG Approach**\\n------------------------------------------\\n\\nThe Graph RAG approach involves two primary stages:\\n\\n1. **Entity Knowledge Graph Construction**: The LLM is used to derive an entity knowledge graph from the source documents [Data: 23]. This stage involves processing the source documents using various techniques, including text processing and analysis [Data: 24].\\n2. **Community Summaries Generation**: The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities [Data: 22, 21].\\n\\n**Advantages over Traditional QFS Methods**\\n------------------------------------------\\n\\nPrior methods for querying and searching large amounts of text (QFS) fail to scale to the quantities of text indexed by typical RAG systems [Data: 14, 15, 16]. In contrast, the Graph RAG approach is designed to handle large datasets and provide accurate question answering results.\\n\\n**Evaluation Metrics**\\n-------------------\\n\\nThe Graph RAG approach is evaluated using a set of evaluation metrics, including those used for question answering models [Data: 10, 4].\\n\\n**Conclusion**\\n----------\\n\\nIn conclusion, the Graph RAG approach offers a scalable solution for indexing private text corpora and providing accurate question answering results. By leveraging LLMs and graph-based indexing techniques, this approach can handle large datasets and provide valuable insights to users.\\n\\nNote: The above response is based on the provided data tables and does not include any information that is not supported by the evidence.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 382, 'prompt_tokens': 1026, 'total_tokens': 1408, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-e81cc083-44c8-43ca-9e77-c80f13e63e77-0', usage_metadata={'input_tokens': 1026, 'output_tokens': 382, 'total_tokens': 1408}))], [ChatGeneration(text=\"Graph Random Access Memory (RAG) is a technique used in graph neural networks to efficiently store and retrieve graph data. Here are some common use cases for Graph RAG:\\n\\n1. **Graph-based recommendation systems**: In recommendation systems, users are often connected by their interactions or preferences. Graph RAG can be used to efficiently store and query these user-item interactions, enabling personalized recommendations.\\n2. **Knowledge graph embeddings**: Knowledge graphs represent entities and their relationships as nodes and edges in a graph. Graph RAG can be used to efficiently compute and store knowledge graph embeddings, which are useful for tasks like entity disambiguation and question answering.\\n3. **Graph-based clustering**: Graph RAG can be used to efficiently cluster nodes in a graph based on their structural similarity. This is useful for tasks like community detection in social networks or identifying clusters of similar products.\\n4. **Graph neural network (GNN) acceleration**: Graph RAG can be used to accelerate the computation of GNNs by storing and retrieving graph data in a more efficient manner, reducing the number of memory accesses and improving overall performance.\\n5. **Graph-based anomaly detection**: Graph RAG can be used to efficiently store and query graph data for anomaly detection tasks, such as identifying unusual patterns or outliers in a graph.\\n6. **Graph-based clustering with node attributes**: In some cases, nodes in a graph have additional attributes that need to be considered during clustering. Graph RAG can be used to efficiently store and retrieve these attributes while performing clustering.\\n7. **Graph-based recommendation systems with item attributes**: Similar to the previous point, Graph RAG can be used to efficiently store and query item attributes in addition to user-item interactions, enabling more accurate recommendations.\\n\\nSome of the benefits of using Graph RAG include:\\n\\n* **Improved memory efficiency**: By storing graph data in a compact and structured manner, Graph RAG reduces memory usage and improves overall performance.\\n* **Faster querying**: Graph RAG enables fast querying and retrieval of graph data, making it suitable for large-scale applications.\\n* **Scalability**: Graph RAG can handle large graphs with millions or even billions of nodes and edges, making it a scalable solution for many use cases.\\n\\nSome popular libraries that implement Graph RAG include:\\n\\n* PyTorch Geometric (PyG)\\n* TensorFlow Graph Rag\\n* GraphRAG (a standalone library)\\n\\nKeep in mind that the specific use case and implementation details may vary depending on the problem you're trying to solve.\", generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content=\"Graph Random Access Memory (RAG) is a technique used in graph neural networks to efficiently store and retrieve graph data. Here are some common use cases for Graph RAG:\\n\\n1. **Graph-based recommendation systems**: In recommendation systems, users are often connected by their interactions or preferences. Graph RAG can be used to efficiently store and query these user-item interactions, enabling personalized recommendations.\\n2. **Knowledge graph embeddings**: Knowledge graphs represent entities and their relationships as nodes and edges in a graph. Graph RAG can be used to efficiently compute and store knowledge graph embeddings, which are useful for tasks like entity disambiguation and question answering.\\n3. **Graph-based clustering**: Graph RAG can be used to efficiently cluster nodes in a graph based on their structural similarity. This is useful for tasks like community detection in social networks or identifying clusters of similar products.\\n4. **Graph neural network (GNN) acceleration**: Graph RAG can be used to accelerate the computation of GNNs by storing and retrieving graph data in a more efficient manner, reducing the number of memory accesses and improving overall performance.\\n5. **Graph-based anomaly detection**: Graph RAG can be used to efficiently store and query graph data for anomaly detection tasks, such as identifying unusual patterns or outliers in a graph.\\n6. **Graph-based clustering with node attributes**: In some cases, nodes in a graph have additional attributes that need to be considered during clustering. Graph RAG can be used to efficiently store and retrieve these attributes while performing clustering.\\n7. **Graph-based recommendation systems with item attributes**: Similar to the previous point, Graph RAG can be used to efficiently store and query item attributes in addition to user-item interactions, enabling more accurate recommendations.\\n\\nSome of the benefits of using Graph RAG include:\\n\\n* **Improved memory efficiency**: By storing graph data in a compact and structured manner, Graph RAG reduces memory usage and improves overall performance.\\n* **Faster querying**: Graph RAG enables fast querying and retrieval of graph data, making it suitable for large-scale applications.\\n* **Scalability**: Graph RAG can handle large graphs with millions or even billions of nodes and edges, making it a scalable solution for many use cases.\\n\\nSome popular libraries that implement Graph RAG include:\\n\\n* PyTorch Geometric (PyG)\\n* TensorFlow Graph Rag\\n* GraphRAG (a standalone library)\\n\\nKeep in mind that the specific use case and implementation details may vary depending on the problem you're trying to solve.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 503, 'prompt_tokens': 19, 'total_tokens': 522, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-6a3ec287-8e25-4b4a-8f39-b93fc7c860d0-0', usage_metadata={'input_tokens': 19, 'output_tokens': 503, 'total_tokens': 522}))]] llm_output={'token_usage': {'completion_tokens': 885, 'prompt_tokens': 1045, 'total_tokens': 1930, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama'} run=[RunInfo(run_id=UUID('e81cc083-44c8-43ca-9e77-c80f13e63e77')), RunInfo(run_id=UUID('6a3ec287-8e25-4b4a-8f39-b93fc7c860d0'))] type='LLMResult'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:357: UserWarning: Unexpected type for token usage: <class 'NoneType'>\n",
      "  warnings.warn(f\"Unexpected type for token usage: {type(new_usage)}\")\n"
     ]
    }
   ],
   "source": [
    "question = \"what is the usecase of Graph RAG\"\n",
    "result = await search_engine.asearch(question)\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the context data used to generate the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>entity</th>\n",
       "      <th>description</th>\n",
       "      <th>number of relationships</th>\n",
       "      <th>in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>TEXT DATA</td>\n",
       "      <td>A dataset of text used for training and testin...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>SOURCE DOCUMENTS</td>\n",
       "      <td>The original texts that are being processed to...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>USER QUESTIONS</td>\n",
       "      <td>Questions asked by users to be answered by the...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>MS</td>\n",
       "      <td>Microsoft is the company behind the Graph RAG ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>GRAPH-BASED TEXT INDEX</td>\n",
       "      <td>A graph-based index of entities and relationsh...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                  entity  \\\n",
       "0   4               TEXT DATA   \n",
       "1  18        SOURCE DOCUMENTS   \n",
       "2   2          USER QUESTIONS   \n",
       "3   8                      MS   \n",
       "4  17  GRAPH-BASED TEXT INDEX   \n",
       "\n",
       "                                         description number of relationships  \\\n",
       "0  A dataset of text used for training and testin...                       2   \n",
       "1  The original texts that are being processed to...                       3   \n",
       "2  Questions asked by users to be answered by the...                       2   \n",
       "3  Microsoft is the company behind the Graph RAG ...                       1   \n",
       "4  A graph-based index of entities and relationsh...                       2   \n",
       "\n",
       "   in_context  \n",
       "0        True  \n",
       "1        True  \n",
       "2        True  \n",
       "3        True  \n",
       "4        True  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.context_data[\"entities\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>description</th>\n",
       "      <th>weight</th>\n",
       "      <th>rank</th>\n",
       "      <th>links</th>\n",
       "      <th>in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>PRIVATE TEXT CORPORA</td>\n",
       "      <td>Question answering is used to index private te...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>TEXT DATA</td>\n",
       "      <td>Question answering models are trained on a lar...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>MODEL TRAINING</td>\n",
       "      <td>Question answering models are trained using th...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>EVALUATION METRICS</td>\n",
       "      <td>Question answering models are evaluated using ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>PRIVATE TEXT CORPORA</td>\n",
       "      <td>USER QUESTIONS</td>\n",
       "      <td>User questions are answered by indexing privat...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                source                target  \\\n",
       "0  1    QUESTION ANSWERING  PRIVATE TEXT CORPORA   \n",
       "1  2    QUESTION ANSWERING             TEXT DATA   \n",
       "2  3    QUESTION ANSWERING        MODEL TRAINING   \n",
       "3  4    QUESTION ANSWERING    EVALUATION METRICS   \n",
       "4  6  PRIVATE TEXT CORPORA        USER QUESTIONS   \n",
       "\n",
       "                                         description weight rank links  \\\n",
       "0  Question answering is used to index private te...    4.0    8     2   \n",
       "1  Question answering models are trained on a lar...    3.0    7     1   \n",
       "2  Question answering models are trained using th...    2.0    7     1   \n",
       "3  Question answering models are evaluated using ...    2.0    7     1   \n",
       "4  User questions are answered by indexing privat...    3.0    5     2   \n",
       "\n",
       "   in_context  \n",
       "0        True  \n",
       "1        True  \n",
       "2        True  \n",
       "3        True  \n",
       "4        True  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.context_data[\"relationships\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Graph RAG Community</td>\n",
       "      <td># Graph RAG Community\\n\\nThe Graph RAG communi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                title                                            content\n",
       "0  1  Graph RAG Community  # Graph RAG Community\\n\\nThe Graph RAG communi..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.context_data[\"reports\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>To combine the strengths of these contrasting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>Our approach uses an LLM to build a graph-base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>An open-source, Python-based implementation of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Prior QFS methods, meanwhile, fail to scale to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                               text\n",
       "0  0  To combine the strengths of these contrasting ...\n",
       "1  6  Our approach uses an LLM to build a graph-base...\n",
       "2  2  An open-source, Python-based implementation of...\n",
       "3  4  Prior QFS methods, meanwhile, fail to scale to..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.context_data[\"sources\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"claims\" in result.context_data:\n",
    "    print(result.context_data[\"claims\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a list of user queries and generates the next candidate questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generator = LocalQuestionGen(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    llm_params=llm_params,\n",
    "    context_builder_params=local_context_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages {'role': 'system', 'content': '\\n---Role---\\n\\nYou are a helpful assistant generating a bulleted list of 5 questions about data in the tables provided.\\n\\n\\n---Data tables---\\n\\n-----Conversation History-----\\nturn|content\\nuser|Tell me about Agent Mercer\\n\\n\\n-----Reports-----\\nid|title|content\\n1|Graph RAG Community|\"# Graph RAG Community\\n\\nThe Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\\n\\n## Graph RAG is a graph-based approach to question answering\\n\\nThe Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\\n\\n## Model training is a crucial aspect of the Graph RAG community\\n\\nModel training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Evaluation metrics are essential for assessing the performance of question answering models\\n\\nThe Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\\n\\n## Graph RAG is implemented in Python\\n\\nThe Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Graph RAG has a strong focus on Microsoft\\n\\nThe Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company\\'s resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\\n\\n\\n-----Entities-----\\nid|entity|description|number of relationships\\n19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\\n4|TEXT DATA|A dataset of text used for training and testing question answering models|2\\n18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\\n1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\\n24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\\n17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\\n15|INDEXING||1\\n12|TEXT||1\\n5|MODEL TRAINING|A process of training machine learning models on a dataset|2\\n2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\\n21|TEXT PROCESSING|The process of extracting information from text documents|1\\n8|MS|Microsoft is the company behind the Graph RAG implementation|1\\n23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\\n13|METHODS||1\\n0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\\n7|HTTPS://AKA.MS/GRAPHRAG||1\\n16|SEARCHING||1\\n6|EVALUATION METRICS|A set of metrics used to evaluate the performance of question answering models|2\\n14|SYSTEMS||1\\n20|LLM||5\\n\\n\\n-----Relationships-----\\nid|source|target|description|weight|rank|links\\n1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|3\\n23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|4\\n2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|3\\n3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|3\\n4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|1\\n20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|4\\n26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|4\\n27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|4\\n6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|1\\n22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|1\\n21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|1\\n24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\\n0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|8\\n5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|8\\n7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|8\\n8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|8\\n9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|8\\n10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|8\\n11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|8\\n13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|8\\n17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|3\\n18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|3\\n19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|3\\n15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|2\\n16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|2\\n25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|1\\n\\n\\n-----Sources-----\\nid|text\\n6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\\n0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\\n4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\\n2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\\n\\n\\n\\n---Goal---\\n\\nGiven a series of example questions provided by the user, generate a bulleted list of 5 candidates for the next question. Use - marks as bullet points.\\n\\nThese candidate questions should represent the most important or urgent information content or themes in the data tables.\\n\\nThe candidate questions should be answerable using the data tables provided, but should not mention any specific data fields or data tables in the question text.\\n\\nIf the user\\'s questions reference several named entities, then each candidate question should reference all named entities.\\n\\n---Example questions---\\n'}\n",
      "input \n",
      "---Role---\n",
      "\n",
      "You are a helpful assistant generating a bulleted list of 5 questions about data in the tables provided.\n",
      "\n",
      "\n",
      "---Data tables---\n",
      "\n",
      "-----Conversation History-----\n",
      "turn|content\n",
      "user|Tell me about Agent Mercer\n",
      "\n",
      "\n",
      "-----Reports-----\n",
      "id|title|content\n",
      "1|Graph RAG Community|\"# Graph RAG Community\n",
      "\n",
      "The Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\n",
      "\n",
      "## Graph RAG is a graph-based approach to question answering\n",
      "\n",
      "The Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\n",
      "\n",
      "## Model training is a crucial aspect of the Graph RAG community\n",
      "\n",
      "Model training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\n",
      "\n",
      "## Evaluation metrics are essential for assessing the performance of question answering models\n",
      "\n",
      "The Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\n",
      "\n",
      "## Graph RAG is implemented in Python\n",
      "\n",
      "The Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\n",
      "\n",
      "## Graph RAG has a strong focus on Microsoft\n",
      "\n",
      "The Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company's resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\n",
      "\n",
      "\n",
      "-----Entities-----\n",
      "id|entity|description|number of relationships\n",
      "19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\n",
      "4|TEXT DATA|A dataset of text used for training and testing question answering models|2\n",
      "18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\n",
      "1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\n",
      "24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\n",
      "17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\n",
      "15|INDEXING||1\n",
      "12|TEXT||1\n",
      "5|MODEL TRAINING|A process of training machine learning models on a dataset|2\n",
      "2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\n",
      "21|TEXT PROCESSING|The process of extracting information from text documents|1\n",
      "8|MS|Microsoft is the company behind the Graph RAG implementation|1\n",
      "23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\n",
      "13|METHODS||1\n",
      "0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\n",
      "7|HTTPS://AKA.MS/GRAPHRAG||1\n",
      "16|SEARCHING||1\n",
      "6|EVALUATION METRICS|A set of metrics used to evaluate the performance of question answering models|2\n",
      "14|SYSTEMS||1\n",
      "20|LLM||5\n",
      "\n",
      "\n",
      "-----Relationships-----\n",
      "id|source|target|description|weight|rank|links\n",
      "1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|3\n",
      "23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|4\n",
      "2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|3\n",
      "3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|3\n",
      "4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|1\n",
      "20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|4\n",
      "26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|4\n",
      "27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|4\n",
      "6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|1\n",
      "22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|1\n",
      "21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|1\n",
      "24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\n",
      "0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|8\n",
      "5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|8\n",
      "7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|8\n",
      "8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|8\n",
      "9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|8\n",
      "10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|8\n",
      "11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|8\n",
      "13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|8\n",
      "17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|3\n",
      "18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|3\n",
      "19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|3\n",
      "15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|2\n",
      "16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|2\n",
      "25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|1\n",
      "\n",
      "\n",
      "-----Sources-----\n",
      "id|text\n",
      "6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\n",
      "0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\n",
      "4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\n",
      "2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\n",
      "\n",
      "\n",
      "\n",
      "---Goal---\n",
      "\n",
      "Given a series of example questions provided by the user, generate a bulleted list of 5 candidates for the next question. Use - marks as bullet points.\n",
      "\n",
      "These candidate questions should represent the most important or urgent information content or themes in the data tables.\n",
      "\n",
      "The candidate questions should be answerable using the data tables provided, but should not mention any specific data fields or data tables in the question text.\n",
      "\n",
      "If the user's questions reference several named entities, then each candidate question should reference all named entities.\n",
      "\n",
      "---Example questions---\n",
      "\n",
      "payload {'messages': [{'content': '\\n---Role---\\n\\nYou are a helpful assistant generating a bulleted list of 5 questions about data in the tables provided.\\n\\n\\n---Data tables---\\n\\n-----Conversation History-----\\nturn|content\\nuser|Tell me about Agent Mercer\\n\\n\\n-----Reports-----\\nid|title|content\\n1|Graph RAG Community|\"# Graph RAG Community\\n\\nThe Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\\n\\n## Graph RAG is a graph-based approach to question answering\\n\\nThe Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\\n\\n## Model training is a crucial aspect of the Graph RAG community\\n\\nModel training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Evaluation metrics are essential for assessing the performance of question answering models\\n\\nThe Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\\n\\n## Graph RAG is implemented in Python\\n\\nThe Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Graph RAG has a strong focus on Microsoft\\n\\nThe Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company\\'s resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\\n\\n\\n-----Entities-----\\nid|entity|description|number of relationships\\n19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\\n4|TEXT DATA|A dataset of text used for training and testing question answering models|2\\n18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\\n1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\\n24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\\n17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\\n15|INDEXING||1\\n12|TEXT||1\\n5|MODEL TRAINING|A process of training machine learning models on a dataset|2\\n2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\\n21|TEXT PROCESSING|The process of extracting information from text documents|1\\n8|MS|Microsoft is the company behind the Graph RAG implementation|1\\n23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\\n13|METHODS||1\\n0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\\n7|HTTPS://AKA.MS/GRAPHRAG||1\\n16|SEARCHING||1\\n6|EVALUATION METRICS|A set of metrics used to evaluate the performance of question answering models|2\\n14|SYSTEMS||1\\n20|LLM||5\\n\\n\\n-----Relationships-----\\nid|source|target|description|weight|rank|links\\n1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|3\\n23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|4\\n2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|3\\n3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|3\\n4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|1\\n20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|4\\n26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|4\\n27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|4\\n6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|1\\n22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|1\\n21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|1\\n24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\\n0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|8\\n5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|8\\n7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|8\\n8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|8\\n9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|8\\n10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|8\\n11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|8\\n13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|8\\n17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|3\\n18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|3\\n19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|3\\n15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|2\\n16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|2\\n25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|1\\n\\n\\n-----Sources-----\\nid|text\\n6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\\n0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\\n4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\\n2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\\n\\n\\n\\n---Goal---\\n\\nGiven a series of example questions provided by the user, generate a bulleted list of 5 candidates for the next question. Use - marks as bullet points.\\n\\nThese candidate questions should represent the most important or urgent information content or themes in the data tables.\\n\\nThe candidate questions should be answerable using the data tables provided, but should not mention any specific data fields or data tables in the question text.\\n\\nIf the user\\'s questions reference several named entities, then each candidate question should reference all named entities.\\n\\n---Example questions---\\n', 'role': 'user'}], 'model': 'llama3.1', 'stream': False, 'n': 1, 'temperature': 0.0, 'streaming': True, 'max_tokens': 2000}\n",
      "messages {'role': 'user', 'content': 'What happens in Dulce military base?'}\n",
      "input What happens in Dulce military base?\n",
      "payload {'messages': [{'content': 'What happens in Dulce military base?', 'role': 'user'}], 'model': 'llama3.1', 'stream': False, 'n': 1, 'temperature': 0.0, 'streaming': True, 'max_tokens': 2000}\n",
      "response generations=[[ChatGeneration(text='Based on the provided data tables and goal, here are five candidate questions that represent important or urgent information content or themes:\\n\\n- How does the Graph RAG approach scale with the generality of user questions?\\n- What techniques are used to process source documents in the Graph RAG system?\\n- Can the Graph RAG approach be trained on a large corpus of text data?\\n- How is the Graph RAG approach evaluated using a set of evaluation metrics?\\n- What is the relationship between the Graph RAG approach and question answering over private text corpora?\\n\\nThese candidate questions are answerable using the provided data tables, but do not mention any specific data fields or data tables in the question text. They also reference all named entities mentioned in the example questions.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='Based on the provided data tables and goal, here are five candidate questions that represent important or urgent information content or themes:\\n\\n- How does the Graph RAG approach scale with the generality of user questions?\\n- What techniques are used to process source documents in the Graph RAG system?\\n- Can the Graph RAG approach be trained on a large corpus of text data?\\n- How is the Graph RAG approach evaluated using a set of evaluation metrics?\\n- What is the relationship between the Graph RAG approach and question answering over private text corpora?\\n\\nThese candidate questions are answerable using the provided data tables, but do not mention any specific data fields or data tables in the question text. They also reference all named entities mentioned in the example questions.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 151, 'prompt_tokens': 1026, 'total_tokens': 1177, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-a1cb11e0-42ab-450d-8825-04e06ce0310a-0', usage_metadata={'input_tokens': 1026, 'output_tokens': 151, 'total_tokens': 1177}))], [ChatGeneration(text='The infamous Dulce Base. There are many conspiracy theories surrounding this topic, and I\\'ll provide an overview of the claims while also separating fact from fiction.\\n\\n**Location:** The alleged Dulce Base is said to be located near the town of Dulce, New Mexico, USA. This area is known for its high desert terrain and has been associated with various UFO sightings over the years.\\n\\n**Conspiracy theories:**\\n\\n1. **Alien base:** One of the most popular conspiracy theories claims that Dulce Base is an underground alien research facility where extraterrestrial beings are being studied by the US government.\\n2. **Reptilian humanoids:** Some believe that the aliens at Dulce Base are reptilian humanoids, also known as \"Grays,\" which have been described in various UFO abduction cases.\\n3. **Secret experiments:** Another theory suggests that the base is used for secret experiments on humans and animals, including mind control and genetic manipulation.\\n4. **Government cover-up:** Many believe that the US government has been covering up the existence of Dulce Base to avoid public panic.\\n\\n**Debunking:**\\n\\n1. **No credible evidence:** Despite numerous claims, there is no concrete evidence to support the existence of an alien base at Dulce or any other location.\\n2. **US Air Force presence:** The US Air Force has a facility near Dulce, known as the Albuquerque Air Route Traffic Control Center (ARTCC), which is responsible for air traffic control in the region. However, this facility is not associated with any secret alien research programs.\\n3. **Local legends and folklore:** Many of the stories surrounding Dulce Base are based on local legends and folklore, which have been exaggerated or distorted over time.\\n\\n**The \"Dulce Book\" controversy:**\\n\\nIn 1994, a book titled \"Dulce: A History of a UFO Incident\" was published by Brinsley Leppington. The book claimed to reveal the existence of an alien base at Dulce and provided detailed descriptions of alleged underground tunnels and facilities. However, many experts have questioned the credibility of this book, citing inconsistencies and lack of evidence.\\n\\n**Conclusion:**\\n\\nWhile there are many conspiracy theories surrounding Dulce Base, there is no concrete evidence to support the claims of an alien research facility or secret government experiments. The stories surrounding this topic are largely based on local legends, folklore, and speculation.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='The infamous Dulce Base. There are many conspiracy theories surrounding this topic, and I\\'ll provide an overview of the claims while also separating fact from fiction.\\n\\n**Location:** The alleged Dulce Base is said to be located near the town of Dulce, New Mexico, USA. This area is known for its high desert terrain and has been associated with various UFO sightings over the years.\\n\\n**Conspiracy theories:**\\n\\n1. **Alien base:** One of the most popular conspiracy theories claims that Dulce Base is an underground alien research facility where extraterrestrial beings are being studied by the US government.\\n2. **Reptilian humanoids:** Some believe that the aliens at Dulce Base are reptilian humanoids, also known as \"Grays,\" which have been described in various UFO abduction cases.\\n3. **Secret experiments:** Another theory suggests that the base is used for secret experiments on humans and animals, including mind control and genetic manipulation.\\n4. **Government cover-up:** Many believe that the US government has been covering up the existence of Dulce Base to avoid public panic.\\n\\n**Debunking:**\\n\\n1. **No credible evidence:** Despite numerous claims, there is no concrete evidence to support the existence of an alien base at Dulce or any other location.\\n2. **US Air Force presence:** The US Air Force has a facility near Dulce, known as the Albuquerque Air Route Traffic Control Center (ARTCC), which is responsible for air traffic control in the region. However, this facility is not associated with any secret alien research programs.\\n3. **Local legends and folklore:** Many of the stories surrounding Dulce Base are based on local legends and folklore, which have been exaggerated or distorted over time.\\n\\n**The \"Dulce Book\" controversy:**\\n\\nIn 1994, a book titled \"Dulce: A History of a UFO Incident\" was published by Brinsley Leppington. The book claimed to reveal the existence of an alien base at Dulce and provided detailed descriptions of alleged underground tunnels and facilities. However, many experts have questioned the credibility of this book, citing inconsistencies and lack of evidence.\\n\\n**Conclusion:**\\n\\nWhile there are many conspiracy theories surrounding Dulce Base, there is no concrete evidence to support the claims of an alien research facility or secret government experiments. The stories surrounding this topic are largely based on local legends, folklore, and speculation.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 485, 'prompt_tokens': 18, 'total_tokens': 503, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-6fd564d4-32d3-4a95-ba68-301241766370-0', usage_metadata={'input_tokens': 18, 'output_tokens': 485, 'total_tokens': 503}))]] llm_output={'token_usage': {'completion_tokens': 636, 'prompt_tokens': 1044, 'total_tokens': 1680, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama'} run=[RunInfo(run_id=UUID('a1cb11e0-42ab-450d-8825-04e06ce0310a')), RunInfo(run_id=UUID('6fd564d4-32d3-4a95-ba68-301241766370'))] type='LLMResult'\n",
      "response.llm_output {'token_usage': {'completion_tokens': 636, 'prompt_tokens': 1044, 'total_tokens': 1680, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama'}\n",
      "generation_texts ['Based on the provided data tables and goal, here are five candidate questions that represent important or urgent information content or themes:\\n\\n- How does the Graph RAG approach scale with the generality of user questions?\\n- What techniques are used to process source documents in the Graph RAG system?\\n- Can the Graph RAG approach be trained on a large corpus of text data?\\n- How is the Graph RAG approach evaluated using a set of evaluation metrics?\\n- What is the relationship between the Graph RAG approach and question answering over private text corpora?\\n\\nThese candidate questions are answerable using the provided data tables, but do not mention any specific data fields or data tables in the question text. They also reference all named entities mentioned in the example questions.']\n",
      "['Based on the provided data tables and goal, here are five candidate questions that represent important or urgent information content or themes:\\n\\n- How does the Graph RAG approach scale with the generality of user questions?\\n- What techniques are used to process source documents in the Graph RAG system?\\n- Can the Graph RAG approach be trained on a large corpus of text data?\\n- How is the Graph RAG approach evaluated using a set of evaluation metrics?\\n- What is the relationship between the Graph RAG approach and question answering over private text corpora?\\n\\nThese candidate questions are answerable using the provided data tables, but do not mention any specific data fields or data tables in the question text. They also reference all named entities mentioned in the example questions.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:357: UserWarning: Unexpected type for token usage: <class 'NoneType'>\n",
      "  warnings.warn(f\"Unexpected type for token usage: {type(new_usage)}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question_history = [\n",
    "    \"Tell me about Agent Mercer\",\n",
    "    \"What happens in Dulce military base?\",\n",
    "]\n",
    "candidate_questions = await question_generator.agenerate(\n",
    "    question_history=question_history, context_data=None, question_count=5\n",
    ")\n",
    "print(candidate_questions.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
