{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright (c) 2024 Microsoft Corporation.\n",
    "# Licensed under the MIT License."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import pandas as pd\n",
    "import tiktoken\n",
    "import ollama\n",
    "from graphrag.query.context_builder.entity_extraction import EntityVectorStoreKey\n",
    "from graphrag.query.indexer_adapters import (\n",
    "    read_indexer_covariates,\n",
    "    read_indexer_entities,\n",
    "    read_indexer_relationships,\n",
    "    read_indexer_reports,\n",
    "    read_indexer_text_units,\n",
    ")\n",
    "from graphrag.query.input.loaders.dfs import (\n",
    "    store_entity_semantic_embeddings,\n",
    ")\n",
    "# from graphrag.query.llm.oai.chat_openai import ChatOpenAI\n",
    "# from graphrag.query.llm.oai.embedding import OpenAIEmbedding\n",
    "# from graphrag.query.llm.oai.typing import OpenaiApiType\n",
    "from graphrag.query.question_gen.local_gen import LocalQuestionGen\n",
    "from graphrag.query.structured_search.local_search.mixed_context import (\n",
    "    LocalSearchMixedContext,\n",
    ")\n",
    "from graphrag.query.structured_search.local_search.search import LocalSearch\n",
    "from graphrag.vector_stores.lancedb import LanceDBVectorStore\n",
    "import ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Local Search Example\n",
    "\n",
    "Local search method generates answers by combining relevant data from the AI-extracted knowledge-graph with text chunks of the raw documents. This method is suitable for questions that require an understanding of specific entities mentioned in the documents (e.g. What are the healing properties of chamomile?)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load text units and graph data tables as context for local search\n",
    "\n",
    "- In this test we first load indexing outputs from parquet files to dataframes, then convert these dataframes into collections of data objects aligning with the knowledge model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load tables to dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIR = \"/Users/luwi/Documents/Code/microsoft_graphrag_local/ragdirs/ragdir_6/output\"#\"./inputs/operation dulce\"\n",
    "LANCEDB_URI = f\"{INPUT_DIR}/lancedb\"\n",
    "\n",
    "COMMUNITY_REPORT_TABLE = \"create_final_community_reports\"\n",
    "ENTITY_TABLE = \"create_final_nodes\"\n",
    "ENTITY_EMBEDDING_TABLE = \"create_final_entities\"\n",
    "RELATIONSHIP_TABLE = \"create_final_relationships\"\n",
    "COVARIATE_TABLE = \"create_final_covariates\"\n",
    "TEXT_UNIT_TABLE = \"create_final_text_units\"\n",
    "COMMUNITY_LEVEL = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['<graphml xmlns=\"http://graphml.graphdrawing.org/xmlns\" xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\" xsi:schemaLocation=\"http://graphml.graphdrawing.org/xmlns http://graphml.graphdrawing.org/xmlns/1.0/graphml.xsd\">\\n  <key id=\"d6\" for=\"edge\" attr.name=\"source_id\" attr.type=\"string\" />\\n  <key id=\"d5\" for=\"edge\" attr.name=\"description\" attr.type=\"string\" />\\n  <key id=\"d4\" for=\"edge\" attr.name=\"weight\" attr.type=\"double\" />\\n  <key id=\"d3\" for=\"node\" attr.name=\"entity_type\" attr.type=\"string\" />\\n  <key id=\"d2\" for=\"node\" attr.name=\"source_id\" attr.type=\"string\" />\\n  <key id=\"d1\" for=\"node\" attr.name=\"description\" attr.type=\"string\" />\\n  <key id=\"d0\" for=\"node\" attr.name=\"type\" attr.type=\"string\" />\\n  <graph edgedefault=\"undirected\">\\n    <node id=\"QUESTION ANSWERING\">\\n      <data key=\"d0\">EVENT</data>\\n      <data key=\"d1\">A method of using a graph to answer questions based on text</data>\\n      <data key=\"d2\">e1e4f0675d6bb822863a64b663629c0f</data>\\n      <data key=\"d3\">EVENT</data>\\n    </node>\\n    <node id=\"PRIVATE TEXT CORPORA\">\\n      <data key=\"d0\">EVENT</data>\\n      <data key=\"d1\">A collection of text that is not publicly available</data>\\n      <data key=\"d2\">e1e4f0675d6bb822863a64b663629c0f</data>\\n      <data key=\"d3\">EVENT</data>\\n    </node>\\n    <node id=\"USER QUESTIONS\">\\n      <data key=\"d0\">EVENT</data>\\n      <data key=\"d1\">Questions asked by users to be answered by the Graph RAG approach</data>\\n      <data key=\"d2\">e1e4f0675d6bb822863a64b663629c0f</data>\\n      <data key=\"d3\">EVENT</data>\\n    </node>\\n    <node id=\"GRAPH RAG\">\\n      <data key=\"d0\" />\\n      <data key=\"d1\">\\n</data>\\n      <data key=\"d2\">bfe1a0b28685e4194ffc64e6bef2501b,e1e4f0675d6bb822863a64b663629c0f</data>\\n    </node>\\n    <node id=\"TEXT DATA\">\\n      <data key=\"d0\">EVENT</data>\\n      <data key=\"d1\">A dataset of text used for training and testing question answering models</data>\\n      <data key=\"d2\">e1e4f0675d6bb822863a64b663629c0f</data>\\n    </node>\\n    <node id=\"MODEL TRAINING\">\\n      <data key=\"d0\">EVENT</data>\\n      <data key=\"d1\">A process of training machine learning models on a dataset</data>\\n      <data key=\"d2\">e1e4f0675d6bb822863a64b663629c0f</data>\\n    </node>\\n    <node id=\"EVALUATION METRICS\">\\n      <data key=\"d0\">EVENT</data>\\n      <data key=\"d1\">A set of metrics used to evaluate the performance of question answering models</data>\\n      <data key=\"d2\">e1e4f0675d6bb822863a64b663629c0f</data>\\n    </node>\\n    <node id=\"HTTPS://AKA.MS/GRAPHRAG\">\\n      <data key=\"d0\" />\\n      <data key=\"d1\" />\\n      <data key=\"d2\">bfe1a0b28685e4194ffc64e6bef2501b</data>\\n    </node>\\n    <node id=\"MS\">\\n      <data key=\"d0\">ORGANIZATION</data>\\n      <data key=\"d1\">Microsoft is the company behind the Graph RAG implementation</data>\\n      <data key=\"d2\">bfe1a0b28685e4194ffc64e6bef2501b</data>\\n    </node>\\n    <node id=\"PYTHON\">\\n      <data key=\"d0\" />\\n      <data key=\"d1\" />\\n      <data key=\"d2\">bfe1a0b28685e4194ffc64e6bef2501b</data>\\n    </node>\\n    <node id=\"QFS\">\\n      <data key=\"d0\" />\\n      <data key=\"d1\" />\\n      <data key=\"d2\">e5e6856d12d6ed343185093279e7d9a0</data>\\n    </node>\\n    <node id=\"RAG SYSTEMS\">\\n      <data key=\"d0\" />\\n      <data key=\"d1\" />\\n      <data key=\"d2\">e5e6856d12d6ed343185093279e7d9a0</data>\\n    </node>\\n    <node id=\"TEXT\">\\n      <data key=\"d0\" />\\n      <data key=\"d1\" />\\n      <data key=\"d2\">e5e6856d12d6ed343185093279e7d9a0</data>\\n    </node>\\n    <node id=\"METHODS\">\\n      <data key=\"d0\" />\\n      <data key=\"d1\" />\\n      <data key=\"d2\">e5e6856d12d6ed343185093279e7d9a0</data>\\n    </node>\\n    <node id=\"SYSTEMS\">\\n      <data key=\"d0\" />\\n      <data key=\"d1\" />\\n      <data key=\"d2\">e5e6856d12d6ed343185093279e7d9a0</data>\\n    </node>\\n    <node id=\"INDEXING\">\\n      <data key=\"d0\" />\\n      <data key=\"d1\" />\\n      <data key=\"d2\">e5e6856d12d6ed343185093279e7d9a0</data>\\n    </node>\\n    <node id=\"SEARCHING\">\\n      <data key=\"d0\" />\\n      <data key=\"d1\" />\\n      <data key=\"d2\">e5e6856d12d6ed343185093279e7d9a0</data>\\n    </node>\\n    <node id=\"GRAPH-BASED TEXT INDEX\">\\n      <data key=\"d0\">EVENT</data>\\n      <data key=\"d1\">A graph-based index of entities and relationships derived from source documents</data>\\n      <data key=\"d2\">43cf19e1c13571010ebd00a8a3191263</data>\\n      <data key=\"d3\">EVENT</data>\\n    </node>\\n    <node id=\"SOURCE DOCUMENTS\">\\n      <data key=\"d0\">EVENT</data>\\n      <data key=\"d1\">The original texts that are being processed to build the entity knowledge graph</data>\\n      <data key=\"d2\">43cf19e1c13571010ebd00a8a3191263</data>\\n      <data key=\"d3\">EVENT</data>\\n    </node>\\n    <node id=\"COMMUNITY SUMMARIES\">\\n      <data key=\"d0\">EVENT</data>\\n      <data key=\"d1\">Pre-generated summaries for groups of closely-related entities</data>\\n      <data key=\"d2\">43cf19e1c13571010ebd00a8a3191263</data>\\n      <data key=\"d3\">EVENT</data>\\n    </node>\\n    <node id=\"LLM\">\\n      <data key=\"d0\" />\\n      <data key=\"d1\" />\\n      <data key=\"d2\">43cf19e1c13571010ebd00a8a3191263</data>\\n    </node>\\n    <node id=\"TEXT PROCESSING\">\\n      <data key=\"d0\">EVENT</data>\\n      <data key=\"d1\">The process of extracting information from text documents</data>\\n      <data key=\"d2\">43cf19e1c13571010ebd00a8a3191263</data>\\n    </node>\\n    <node id=\"ENTITY KNOWLEDGE GRAPH\">\\n      <data key=\"d0\" />\\n      <data key=\"d1\" />\\n      <data key=\"d2\">43cf19e1c13571010ebd00a8a3191263</data>\\n    </node>\\n    <node id=\"DOCUMENT ANALYSIS TOOL\">\\n      <data key=\"d0\">EVENT</data>\\n      <data key=\"d1\">A tool for analyzing and extracting information from text documents</data>\\n      <data key=\"d2\">43cf19e1c13571010ebd00a8a3191263</data>\\n    </node>\\n    <node id=\"ENTITY EXTRACTION ALGORITHM\">\\n      <data key=\"d0\">EVENT</data>\\n      <data key=\"d1\">A algorithm for extracting entities from text documents</data>\\n      <data key=\"d2\">43cf19e1c13571010ebd00a8a3191263</data>\\n    </node>\\n    <edge source=\"QUESTION ANSWERING\" target=\"GRAPH RAG\">\\n      <data key=\"d4\">16.0</data>\\n      <data key=\"d5\">The Graph RAG approach uses question answering as a method to answer user questions</data>\\n      <data key=\"d6\">e1e4f0675d6bb822863a64b663629c0f</data>\\n    </edge>\\n    <edge source=\"QUESTION ANSWERING\" target=\"PRIVATE TEXT CORPORA\">\\n      <data key=\"d4\">4.0</data>\\n      <data key=\"d5\">Question answering is used to index private text corpora using the Graph RAG approach</data>\\n      <data key=\"d6\">e1e4f0675d6bb822863a64b663629c0f</data>\\n    </edge>\\n    <edge source=\"QUESTION ANSWERING\" target=\"TEXT DATA\">\\n      <data key=\"d4\">3.0</data>\\n      <data key=\"d5\">Question answering models are trained on a large corpus of text data using the Graph RAG approach</data>\\n      <data key=\"d6\">e1e4f0675d6bb822863a64b663629c0f</data>\\n    </edge>\\n    <edge source=\"QUESTION ANSWERING\" target=\"MODEL TRAINING\">\\n      <data key=\"d4\">2.0</data>\\n      <data key=\"d5\">Question answering models are trained using the Graph RAG approach and a model training process</data>\\n      <data key=\"d6\">e1e4f0675d6bb822863a64b663629c0f</data>\\n    </edge>\\n    <edge source=\"QUESTION ANSWERING\" target=\"EVALUATION METRICS\">\\n      <data key=\"d4\">2.0</data>\\n      <data key=\"d5\">Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics</data>\\n      <data key=\"d6\">e1e4f0675d6bb822863a64b663629c0f</data>\\n    </edge>\\n    <edge source=\"PRIVATE TEXT CORPORA\" target=\"GRAPH RAG\">\\n      <data key=\"d4\">10.0</data>\\n      <data key=\"d5\">The Graph RAG approach is used to index private text corpora</data>\\n      <data key=\"d6\">e1e4f0675d6bb822863a64b663629c0f</data>\\n    </edge>\\n    <edge source=\"PRIVATE TEXT CORPORA\" target=\"USER QUESTIONS\">\\n      <data key=\"d4\">3.0</data>\\n      <data key=\"d5\">User questions are answered by indexing private text corpora using the Graph RAG approach</data>\\n      <data key=\"d6\">e1e4f0675d6bb822863a64b663629c0f</data>\\n    </edge>\\n    <edge source=\"USER QUESTIONS\" target=\"GRAPH RAG\">\\n      <data key=\"d4\">6.0</data>\\n      <data key=\"d5\">The Graph RAG approach scales with the generality of user questions</data>\\n      <data key=\"d6\">e1e4f0675d6bb822863a64b663629c0f</data>\\n    </edge>\\n    <edge source=\"GRAPH RAG\" target=\"TEXT DATA\">\\n      <data key=\"d4\">4.0</data>\\n      <data key=\"d5\">The Graph RAG approach is trained on a large corpus of text data</data>\\n      <data key=\"d6\">e1e4f0675d6bb822863a64b663629c0f</data>\\n    </edge>\\n    <edge source=\"GRAPH RAG\" target=\"MODEL TRAINING\">\\n      <data key=\"d4\">2.0</data>\\n      <data key=\"d5\">The Graph RAG approach is trained using a model training process</data>\\n      <data key=\"d6\">e1e4f0675d6bb822863a64b663629c0f</data>\\n    </edge>\\n    <edge source=\"GRAPH RAG\" target=\"EVALUATION METRICS\">\\n      <data key=\"d4\">2.0</data>\\n      <data key=\"d5\">The Graph RAG approach is evaluated using a set of evaluation metrics</data>\\n      <data key=\"d6\">e1e4f0675d6bb822863a64b663629c0f</data>\\n    </edge>\\n    <edge source=\"GRAPH RAG\" target=\"HTTPS://AKA.MS/GRAPHRAG\">\\n      <data key=\"d4\">2.0</data>\\n      <data key=\"d5\">Graph RAG can be accessed at this URL</data>\\n      <data key=\"d6\">bfe1a0b28685e4194ffc64e6bef2501b</data>\\n    </edge>\\n    <edge source=\"GRAPH RAG\" target=\"PYTHON\">\\n      <data key=\"d4\">8.0</data>\\n      <data key=\"d5\">Graph RAG is implemented in Python</data>\\n      <data key=\"d6\">bfe1a0b28685e4194ffc64e6bef2501b</data>\\n    </edge>\\n    <edge source=\"GRAPH RAG\" target=\"MS\">\\n      <data key=\"d4\">1.0</data>\\n      <data key=\"d5\">Graph RAG is a Microsoft implementation</data>\\n      <data key=\"d6\">bfe1a0b28685e4194ffc64e6bef2501b</data>\\n    </edge>\\n    <edge source=\"QFS\" target=\"RAG SYSTEMS\">\\n      <data key=\"d4\">3.0</data>\\n      <data key=\"d5\">QFS methods fail to scale to the quantities of text indexed by typical RAG systems</data>\\n      <data key=\"d6\">e5e6856d12d6ed343185093279e7d9a0</data>\\n    </edge>\\n    <edge source=\"QFS\" target=\"METHODS\">\\n      <data key=\"d4\">1.0</data>\\n      <data key=\"d5\">QFS refers to a method for querying and searching large amounts of text</data>\\n      <data key=\"d6\">e5e6856d12d6ed343185093279e7d9a0</data>\\n    </edge>\\n    <edge source=\"QFS\" target=\"SEARCHING\">\\n      <data key=\"d4\">1.0</data>\\n      <data key=\"d5\">QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult</data>\\n      <data key=\"d6\">e5e6856d12d6ed343185093279e7d9a0</data>\\n    </edge>\\n    <edge source=\"RAG SYSTEMS\" target=\"TEXT\">\\n      <data key=\"d4\">1.0</data>\\n      <data key=\"d5\">RAG Systems index large amounts of text</data>\\n      <data key=\"d6\">e5e6856d12d6ed343185093279e7d9a0</data>\\n    </edge>\\n    <edge source=\"RAG SYSTEMS\" target=\"SYSTEMS\">\\n      <data key=\"d4\">1.0</data>\\n      <data key=\"d5\">RAG Systems are a type of search engine system</data>\\n      <data key=\"d6\">e5e6856d12d6ed343185093279e7d9a0</data>\\n    </edge>\\n    <edge source=\"RAG SYSTEMS\" target=\"INDEXING\">\\n      <data key=\"d4\">1.0</data>\\n      <data key=\"d5\">RAG Systems index large amounts of text</data>\\n      <data key=\"d6\">e5e6856d12d6ed343185093279e7d9a0</data>\\n    </edge>\\n    <edge source=\"GRAPH-BASED TEXT INDEX\" target=\"LLM\">\\n      <data key=\"d4\">16.0</data>\\n      <data key=\"d5\">The LLM is used to build a graph-based text index in two stages</data>\\n      <data key=\"d6\">43cf19e1c13571010ebd00a8a3191263</data>\\n    </edge>\\n    <edge source=\"GRAPH-BASED TEXT INDEX\" target=\"COMMUNITY SUMMARIES\">\\n      <data key=\"d4\">2.0</data>\\n      <data key=\"d5\">The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities</data>\\n      <data key=\"d6\">43cf19e1c13571010ebd00a8a3191263</data>\\n    </edge>\\n    <edge source=\"SOURCE DOCUMENTS\" target=\"COMMUNITY SUMMARIES\">\\n      <data key=\"d4\">10.0</data>\\n      <data key=\"d5\">Community summaries are pre-generated for all groups of closely-related entities from source documents</data>\\n      <data key=\"d6\">43cf19e1c13571010ebd00a8a3191263</data>\\n    </edge>\\n    <edge source=\"SOURCE DOCUMENTS\" target=\"LLM\">\\n      <data key=\"d4\">16.0</data>\\n      <data key=\"d5\">The LLM is used to derive an entity knowledge graph from the source documents</data>\\n      <data key=\"d6\">43cf19e1c13571010ebd00a8a3191263</data>\\n    </edge>\\n    <edge source=\"SOURCE DOCUMENTS\" target=\"TEXT PROCESSING\">\\n      <data key=\"d4\">5.0</data>\\n      <data key=\"d5\">Source documents are processed using various techniques</data>\\n      <data key=\"d6\">43cf19e1c13571010ebd00a8a3191263</data>\\n    </edge>\\n    <edge source=\"LLM\" target=\"ENTITY KNOWLEDGE GRAPH\">\\n      <data key=\"d4\">8.0</data>\\n      <data key=\"d5\">The LLM is used to build the entity knowledge graph</data>\\n      <data key=\"d6\">43cf19e1c13571010ebd00a8a3191263</data>\\n    </edge>\\n    <edge source=\"LLM\" target=\"DOCUMENT ANALYSIS TOOL\">\\n      <data key=\"d4\">8.0</data>\\n      <data key=\"d5\">The LLM is used in conjunction with a document analysis tool to extract entities and relationships</data>\\n      <data key=\"d6\">43cf19e1c13571010ebd00a8a3191263</data>\\n    </edge>\\n    <edge source=\"LLM\" target=\"ENTITY EXTRACTION ALGORITHM\">\\n      <data key=\"d4\">1.0</data>\\n      <data key=\"d5\">The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships</data>\\n      <data key=\"d6\">43cf19e1c13571010ebd00a8a3191263</data>\\n    </edge>\\n  </graph>\\n</graphml>']],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "entity_df = pd.read_parquet(f\"/Users/luwi/Documents/Code/microsoft_graphrag_local/ragdirs/ragdir_2/output/create_base_extracted_entities.parquet\")\n",
    "entity_df.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/Users/luwi/Documents/Code/microsoft_graphrag_local/ragdirs/ragdir_6/output/create_final_nodes.parquet'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# read nodes table to get community and degree data\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m entity_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_parquet\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mINPUT_DIR\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mENTITY_TABLE\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m.parquet\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m entity_embedding_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mread_parquet(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mINPUT_DIR\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m/\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mENTITY_EMBEDDING_TABLE\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.parquet\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      5\u001b[0m entities \u001b[38;5;241m=\u001b[39m read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
      "File \u001b[0;32m~/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages/pandas/io/parquet.py:667\u001b[0m, in \u001b[0;36mread_parquet\u001b[0;34m(path, engine, columns, storage_options, use_nullable_dtypes, dtype_backend, filesystem, filters, **kwargs)\u001b[0m\n\u001b[1;32m    664\u001b[0m     use_nullable_dtypes \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[1;32m    665\u001b[0m check_dtype_backend(dtype_backend)\n\u001b[0;32m--> 667\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimpl\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    668\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    669\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolumns\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolumns\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    670\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilters\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilters\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    671\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    672\u001b[0m \u001b[43m    \u001b[49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43muse_nullable_dtypes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    673\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype_backend\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdtype_backend\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    674\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    675\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    676\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages/pandas/io/parquet.py:267\u001b[0m, in \u001b[0;36mPyArrowImpl.read\u001b[0;34m(self, path, columns, filters, use_nullable_dtypes, dtype_backend, storage_options, filesystem, **kwargs)\u001b[0m\n\u001b[1;32m    264\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m manager \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124marray\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m    265\u001b[0m     to_pandas_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124msplit_blocks\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[assignment]\u001b[39;00m\n\u001b[0;32m--> 267\u001b[0m path_or_handle, handles, filesystem \u001b[38;5;241m=\u001b[39m \u001b[43m_get_path_or_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    268\u001b[0m \u001b[43m    \u001b[49m\u001b[43mpath\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    269\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfilesystem\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    270\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    271\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrb\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    272\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    273\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    274\u001b[0m     pa_table \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi\u001b[38;5;241m.\u001b[39mparquet\u001b[38;5;241m.\u001b[39mread_table(\n\u001b[1;32m    275\u001b[0m         path_or_handle,\n\u001b[1;32m    276\u001b[0m         columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    279\u001b[0m         \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m    280\u001b[0m     )\n",
      "File \u001b[0;32m~/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages/pandas/io/parquet.py:140\u001b[0m, in \u001b[0;36m_get_path_or_handle\u001b[0;34m(path, fs, storage_options, mode, is_dir)\u001b[0m\n\u001b[1;32m    130\u001b[0m handles \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    131\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    132\u001b[0m     \u001b[38;5;129;01mnot\u001b[39;00m fs\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_dir\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    138\u001b[0m     \u001b[38;5;66;03m# fsspec resources can also point to directories\u001b[39;00m\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m# this branch is used for example when reading from non-fsspec URLs\u001b[39;00m\n\u001b[0;32m--> 140\u001b[0m     handles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    141\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpath_or_handle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstorage_options\u001b[49m\n\u001b[1;32m    142\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    143\u001b[0m     fs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    144\u001b[0m     path_or_handle \u001b[38;5;241m=\u001b[39m handles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m~/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages/pandas/io/common.py:882\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[1;32m    874\u001b[0m             handle,\n\u001b[1;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    879\u001b[0m         )\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m--> 882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    883\u001b[0m     handles\u001b[38;5;241m.\u001b[39mappend(handle)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;66;03m# Convert BytesIO or file objects passed with an encoding\u001b[39;00m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/Users/luwi/Documents/Code/microsoft_graphrag_local/ragdirs/ragdir_6/output/create_final_nodes.parquet'"
     ]
    }
   ],
   "source": [
    "# read nodes table to get community and degree data\n",
    "entity_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_TABLE}.parquet\")\n",
    "entity_embedding_df = pd.read_parquet(f\"{INPUT_DIR}/{ENTITY_EMBEDDING_TABLE}.parquet\")\n",
    "\n",
    "entities = read_indexer_entities(entity_df, entity_embedding_df, COMMUNITY_LEVEL)\n",
    "\n",
    "# load description embeddings to an in-memory lancedb vectorstore\n",
    "# to connect to a remote db, specify url and port values.\n",
    "description_embedding_store = LanceDBVectorStore(\n",
    "    collection_name=\"entity_description_embeddings\",\n",
    ")\n",
    "description_embedding_store.connect(db_uri=LANCEDB_URI)\n",
    "entity_description_embeddings = store_entity_semantic_embeddings(\n",
    "    entities=entities, vectorstore=description_embedding_store\n",
    ")\n",
    "\n",
    "print(f\"Entity count: {len(entity_df)}\")\n",
    "entity_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read relationships"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Relationship count: 28\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>weight</th>\n",
       "      <th>description</th>\n",
       "      <th>text_unit_ids</th>\n",
       "      <th>id</th>\n",
       "      <th>human_readable_id</th>\n",
       "      <th>source_degree</th>\n",
       "      <th>target_degree</th>\n",
       "      <th>rank</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>GRAPH RAG</td>\n",
       "      <td>16.0</td>\n",
       "      <td>The Graph RAG approach uses question answering...</td>\n",
       "      <td>[e1e4f0675d6bb822863a64b663629c0f]</td>\n",
       "      <td>3db243c5a3b9469687d7b3e6beebfdd4</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>9</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>PRIVATE TEXT CORPORA</td>\n",
       "      <td>4.0</td>\n",
       "      <td>Question answering is used to index private te...</td>\n",
       "      <td>[e1e4f0675d6bb822863a64b663629c0f]</td>\n",
       "      <td>79dcf8d8b7ce4d17a80db0f448cc97d0</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>3</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>TEXT DATA</td>\n",
       "      <td>3.0</td>\n",
       "      <td>Question answering models are trained on a lar...</td>\n",
       "      <td>[e1e4f0675d6bb822863a64b663629c0f]</td>\n",
       "      <td>32f3ebbf64c74a7baa1cfd1eb4ccd95a</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>MODEL TRAINING</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Question answering models are trained using th...</td>\n",
       "      <td>[e1e4f0675d6bb822863a64b663629c0f]</td>\n",
       "      <td>949ca6e4e6e94bf3980b26832735b233</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>EVALUATION METRICS</td>\n",
       "      <td>2.0</td>\n",
       "      <td>Question answering models are evaluated using ...</td>\n",
       "      <td>[e1e4f0675d6bb822863a64b663629c0f]</td>\n",
       "      <td>06a15aca87bf4691a0540036abef4ec0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               source                target  weight  \\\n",
       "0  QUESTION ANSWERING             GRAPH RAG    16.0   \n",
       "1  QUESTION ANSWERING  PRIVATE TEXT CORPORA     4.0   \n",
       "2  QUESTION ANSWERING             TEXT DATA     3.0   \n",
       "3  QUESTION ANSWERING        MODEL TRAINING     2.0   \n",
       "4  QUESTION ANSWERING    EVALUATION METRICS     2.0   \n",
       "\n",
       "                                         description  \\\n",
       "0  The Graph RAG approach uses question answering...   \n",
       "1  Question answering is used to index private te...   \n",
       "2  Question answering models are trained on a lar...   \n",
       "3  Question answering models are trained using th...   \n",
       "4  Question answering models are evaluated using ...   \n",
       "\n",
       "                        text_unit_ids                                id  \\\n",
       "0  [e1e4f0675d6bb822863a64b663629c0f]  3db243c5a3b9469687d7b3e6beebfdd4   \n",
       "1  [e1e4f0675d6bb822863a64b663629c0f]  79dcf8d8b7ce4d17a80db0f448cc97d0   \n",
       "2  [e1e4f0675d6bb822863a64b663629c0f]  32f3ebbf64c74a7baa1cfd1eb4ccd95a   \n",
       "3  [e1e4f0675d6bb822863a64b663629c0f]  949ca6e4e6e94bf3980b26832735b233   \n",
       "4  [e1e4f0675d6bb822863a64b663629c0f]  06a15aca87bf4691a0540036abef4ec0   \n",
       "\n",
       "  human_readable_id  source_degree  target_degree  rank  \n",
       "0                 0              5              9    14  \n",
       "1                 1              5              3     8  \n",
       "2                 2              5              2     7  \n",
       "3                 3              5              2     7  \n",
       "4                 4              5              2     7  "
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relationship_df = pd.read_parquet(f\"{INPUT_DIR}/{RELATIONSHIP_TABLE}.parquet\")\n",
    "relationships = read_indexer_relationships(relationship_df)\n",
    "\n",
    "print(f\"Relationship count: {len(relationship_df)}\")\n",
    "relationship_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOTE: covariates are turned off by default, because they generally need prompt tuning to be valuable\n",
    "# Please see the GRAPHRAG_CLAIM_* settings\n",
    "\n",
    "# covariate_df = pd.read_parquet(f\"{INPUT_DIR}/{COVARIATE_TABLE}.parquet\")\n",
    "\n",
    "# claims = read_indexer_covariates(covariate_df)\n",
    "\n",
    "# print(f\"Claim records: {len(claims)}\")\n",
    "# covariates = {\"claims\": claims}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read community reports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Report records: 2\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>community</th>\n",
       "      <th>full_content</th>\n",
       "      <th>level</th>\n",
       "      <th>rank</th>\n",
       "      <th>title</th>\n",
       "      <th>rank_explanation</th>\n",
       "      <th>summary</th>\n",
       "      <th>findings</th>\n",
       "      <th>full_content_json</th>\n",
       "      <th>id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td># Private Text Corpora Community\\n\\nThis commu...</td>\n",
       "      <td>0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>Private Text Corpora Community</td>\n",
       "      <td>The impact severity rating is moderate due to ...</td>\n",
       "      <td>This community revolves around a collection of...</td>\n",
       "      <td>[{'explanation': 'The Graph RAG approach is be...</td>\n",
       "      <td>{\\n    \"title\": \"Private Text Corpora Communit...</td>\n",
       "      <td>b054475a-a026-4260-9d93-6abf954a123d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td># Graph RAG Community\\n\\nThe Graph RAG communi...</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>Graph RAG Community</td>\n",
       "      <td>The Graph RAG community has a moderate impact ...</td>\n",
       "      <td>The Graph RAG community revolves around a grap...</td>\n",
       "      <td>[{'explanation': 'The Graph RAG community cent...</td>\n",
       "      <td>{\\n    \"title\": \"Graph RAG Community\",\\n    \"s...</td>\n",
       "      <td>cc10104e-5ecc-4e6a-a027-7acd2448a9d9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  community                                       full_content  level  rank  \\\n",
       "0         0  # Private Text Corpora Community\\n\\nThis commu...      0   6.0   \n",
       "1         1  # Graph RAG Community\\n\\nThe Graph RAG communi...      0   8.0   \n",
       "\n",
       "                            title  \\\n",
       "0  Private Text Corpora Community   \n",
       "1             Graph RAG Community   \n",
       "\n",
       "                                    rank_explanation  \\\n",
       "0  The impact severity rating is moderate due to ...   \n",
       "1  The Graph RAG community has a moderate impact ...   \n",
       "\n",
       "                                             summary  \\\n",
       "0  This community revolves around a collection of...   \n",
       "1  The Graph RAG community revolves around a grap...   \n",
       "\n",
       "                                            findings  \\\n",
       "0  [{'explanation': 'The Graph RAG approach is be...   \n",
       "1  [{'explanation': 'The Graph RAG community cent...   \n",
       "\n",
       "                                   full_content_json  \\\n",
       "0  {\\n    \"title\": \"Private Text Corpora Communit...   \n",
       "1  {\\n    \"title\": \"Graph RAG Community\",\\n    \"s...   \n",
       "\n",
       "                                     id  \n",
       "0  b054475a-a026-4260-9d93-6abf954a123d  \n",
       "1  cc10104e-5ecc-4e6a-a027-7acd2448a9d9  "
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "report_df = pd.read_parquet(f\"{INPUT_DIR}/{COMMUNITY_REPORT_TABLE}.parquet\")\n",
    "reports = read_indexer_reports(report_df, entity_df, COMMUNITY_LEVEL)\n",
    "\n",
    "print(f\"Report records: {len(report_df)}\")\n",
    "report_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read text units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text unit records: 8\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>n_tokens</th>\n",
       "      <th>document_ids</th>\n",
       "      <th>entity_ids</th>\n",
       "      <th>relationship_ids</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e1e4f0675d6bb822863a64b663629c0f</td>\n",
       "      <td>To combine the strengths of these contrasting ...</td>\n",
       "      <td>44</td>\n",
       "      <td>[1730bed2b2faeda8ee1e88c01ac584b3]</td>\n",
       "      <td>[40740b36141645ae854cc406f7ff129f, d1645731adb...</td>\n",
       "      <td>[3db243c5a3b9469687d7b3e6beebfdd4, 79dcf8d8b7c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>04becef81fb7d21fbe198dfca4e4d159</td>\n",
       "      <td>For a class of global sensemaking questions ov...</td>\n",
       "      <td>46</td>\n",
       "      <td>[889e75d03fdb3c2c486219d8495678ee]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>bfe1a0b28685e4194ffc64e6bef2501b</td>\n",
       "      <td>An open-source, Python-based implementation of...</td>\n",
       "      <td>26</td>\n",
       "      <td>[94463dbd2b03a19805bf94f0c8552c47]</td>\n",
       "      <td>[46f5bfc902b54297928abdd085d020ff, 9c7fba7797a...</td>\n",
       "      <td>[f026b8337e8544cf93dacebf9247d574, c6ac85dbd97...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>7bf2b315168e3ec08a740d7638621161</td>\n",
       "      <td>Given a question, each community summary is us...</td>\n",
       "      <td>30</td>\n",
       "      <td>[bec823c0460d762ebedd21cd46ec9d68]</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>e5e6856d12d6ed343185093279e7d9a0</td>\n",
       "      <td>Prior QFS methods, meanwhile, fail to scale to...</td>\n",
       "      <td>22</td>\n",
       "      <td>[ca922d8b1c0c462898eb677966f148fd]</td>\n",
       "      <td>[cc6c98e369bc420a9a31101e387f8927, 34e6a3da1ad...</td>\n",
       "      <td>[33f2b5da86154f098dbfb024ead2be02, 9eaa628eb25...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 id  \\\n",
       "0  e1e4f0675d6bb822863a64b663629c0f   \n",
       "1  04becef81fb7d21fbe198dfca4e4d159   \n",
       "2  bfe1a0b28685e4194ffc64e6bef2501b   \n",
       "3  7bf2b315168e3ec08a740d7638621161   \n",
       "4  e5e6856d12d6ed343185093279e7d9a0   \n",
       "\n",
       "                                                text  n_tokens  \\\n",
       "0  To combine the strengths of these contrasting ...        44   \n",
       "1  For a class of global sensemaking questions ov...        46   \n",
       "2  An open-source, Python-based implementation of...        26   \n",
       "3  Given a question, each community summary is us...        30   \n",
       "4  Prior QFS methods, meanwhile, fail to scale to...        22   \n",
       "\n",
       "                         document_ids  \\\n",
       "0  [1730bed2b2faeda8ee1e88c01ac584b3]   \n",
       "1  [889e75d03fdb3c2c486219d8495678ee]   \n",
       "2  [94463dbd2b03a19805bf94f0c8552c47]   \n",
       "3  [bec823c0460d762ebedd21cd46ec9d68]   \n",
       "4  [ca922d8b1c0c462898eb677966f148fd]   \n",
       "\n",
       "                                          entity_ids  \\\n",
       "0  [40740b36141645ae854cc406f7ff129f, d1645731adb...   \n",
       "1                                               None   \n",
       "2  [46f5bfc902b54297928abdd085d020ff, 9c7fba7797a...   \n",
       "3                                               None   \n",
       "4  [cc6c98e369bc420a9a31101e387f8927, 34e6a3da1ad...   \n",
       "\n",
       "                                    relationship_ids  \n",
       "0  [3db243c5a3b9469687d7b3e6beebfdd4, 79dcf8d8b7c...  \n",
       "1                                               None  \n",
       "2  [f026b8337e8544cf93dacebf9247d574, c6ac85dbd97...  \n",
       "3                                               None  \n",
       "4  [33f2b5da86154f098dbfb024ead2be02, 9eaa628eb25...  "
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_unit_df = pd.read_parquet(f\"{INPUT_DIR}/{TEXT_UNIT_TABLE}.parquet\")\n",
    "text_units = read_indexer_text_units(text_unit_df)\n",
    "\n",
    "print(f\"Text unit records: {len(text_unit_df)}\")\n",
    "text_unit_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pypi.ngc.nvidia.com\n",
      "Collecting langchain_ollama\n",
      "  Downloading langchain_ollama-0.2.0-py3-none-any.whl.metadata (1.8 kB)\n",
      "Requirement already satisfied: langchain-core<0.4.0,>=0.3.0 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from langchain_ollama) (0.3.5)\n",
      "Requirement already satisfied: ollama<1,>=0.3.0 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from langchain_ollama) (0.3.3)\n",
      "Requirement already satisfied: PyYAML>=5.3 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_ollama) (6.0.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_ollama) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.125 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_ollama) (0.1.125)\n",
      "Requirement already satisfied: packaging<25,>=23.2 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_ollama) (24.1)\n",
      "Requirement already satisfied: pydantic<3.0.0,>=2.5.2 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_ollama) (2.9.2)\n",
      "Collecting tenacity!=8.4.0,<9.0.0,>=8.1.0 (from langchain-core<0.4.0,>=0.3.0->langchain_ollama)\n",
      "  Downloading tenacity-8.5.0-py3-none-any.whl.metadata (1.2 kB)\n",
      "Requirement already satisfied: typing-extensions>=4.7 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from langchain-core<0.4.0,>=0.3.0->langchain_ollama) (4.12.2)\n",
      "Requirement already satisfied: httpx<0.28.0,>=0.27.0 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from ollama<1,>=0.3.0->langchain_ollama) (0.27.2)\n",
      "Requirement already satisfied: anyio in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain_ollama) (4.6.0)\n",
      "Requirement already satisfied: certifi in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain_ollama) (2024.8.30)\n",
      "Requirement already satisfied: httpcore==1.* in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain_ollama) (1.0.5)\n",
      "Requirement already satisfied: idna in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain_ollama) (3.10)\n",
      "Requirement already satisfied: sniffio in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain_ollama) (1.3.1)\n",
      "Requirement already satisfied: h11<0.15,>=0.13 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from httpcore==1.*->httpx<0.28.0,>=0.27.0->ollama<1,>=0.3.0->langchain_ollama) (0.14.0)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.4.0,>=0.3.0->langchain_ollama) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.0->langchain_ollama) (3.10.7)\n",
      "Requirement already satisfied: requests<3,>=2 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.0->langchain_ollama) (2.32.3)\n",
      "Requirement already satisfied: annotated-types>=0.6.0 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.0->langchain_ollama) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.23.4 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.5.2->langchain-core<0.4.0,>=0.3.0->langchain_ollama) (2.23.4)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.0->langchain_ollama) (3.3.2)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages (from requests<3,>=2->langsmith<0.2.0,>=0.1.125->langchain-core<0.4.0,>=0.3.0->langchain_ollama) (2.2.3)\n",
      "Downloading langchain_ollama-0.2.0-py3-none-any.whl (14 kB)\n",
      "Downloading tenacity-8.5.0-py3-none-any.whl (28 kB)\n",
      "Installing collected packages: tenacity, langchain_ollama\n",
      "  Attempting uninstall: tenacity\n",
      "    Found existing installation: tenacity 9.0.0\n",
      "    Uninstalling tenacity-9.0.0:\n",
      "      Successfully uninstalled tenacity-9.0.0\n",
      "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
      "graphrag 0.0.1.dev185 requires tenacity<10.0.0,>=9.0.0, but you have tenacity 8.5.0 which is incompatible.\u001b[0m\u001b[31m\n",
      "\u001b[0mSuccessfully installed langchain_ollama-0.2.0 tenacity-8.5.0\n",
      "\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.1.2\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m24.2\u001b[0m\n",
      "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = '\\n-Goal-\\nGiven a text document that is potentially relevant to this activity and a list of entity types, identify all entities of those types from the text and all relationships among the identified entities.\\n \\n-Steps-\\n1. Identify all entities. For each identified entity, extract the following information:\\n- entity_name: Name of the entity, capitalized\\n- entity_type: One of the following types: [organization,person,geo,event]\\n- entity_description: Comprehensive description of the entity\\'s attributes and activities\\nFormat each entity as (\"entity\"<|><entity_name><|><entity_type><|><entity_description>)\\n \\n2. From the entities identified in step 1, identify all pairs of (source_entity, target_entity) that are *clearly related* to each other.\\nFor each pair of related entities, extract the following information:\\n- source_entity: name of the source entity, as identified in step 1\\n- target_entity: name of the target entity, as identified in step 1\\n- relationship_description: explanation as to why you think the source entity and the target entity are related to each other\\n- relationship_strength: a numeric score indicating strength of the relationship between the source entity and target entity\\n Format each relationship as (\"relationship\"<|><source_entity><|><target_entity><|><relationship_description><|><relationship_strength>)\\n \\n3. Return output in English as a single list of all the entities and relationships identified in steps 1 and 2. Use **##** as the list delimiter.\\n \\n4. When finished, output <|COMPLETE|>\\n \\n######################\\n-Examples-\\n######################\\nExample 1:\\nEntity_types: ORGANIZATION,PERSON\\nText:\\nThe Verdantis\\'s Central Institution is scheduled to meet on Monday and Thursday, with the institution planning to release its latest policy decision on Thursday at 1:30 p.m. PDT, followed by a press conference where Central Institution Chair Martin Smith will take questions. Investors expect the Market Strategy Committee to hold its benchmark interest rate steady in a range of 3.5%-3.75%.\\n######################\\nOutput:\\n(\"entity\"<|>CENTRAL INSTITUTION<|>ORGANIZATION<|>The Central Institution is the Federal Reserve of Verdantis, which is setting interest rates on Monday and Thursday)\\n##\\n(\"entity\"<|>MARTIN SMITH<|>PERSON<|>Martin Smith is the chair of the Central Institution)\\n##\\n(\"entity\"<|>MARKET STRATEGY COMMITTEE<|>ORGANIZATION<|>The Central Institution committee makes key decisions about interest rates and the growth of Verdantis\\'s money supply)\\n##\\n(\"relationship\"<|>MARTIN SMITH<|>CENTRAL INSTITUTION<|>Martin Smith is the Chair of the Central Institution and will answer questions at a press conference<|>9)\\n<|COMPLETE|>\\n\\n######################\\nExample 2:\\nEntity_types: ORGANIZATION\\nText:\\nTechGlobal\\'s (TG) stock skyrocketed in its opening day on the Global Exchange Thursday. But IPO experts warn that the semiconductor corporation\\'s debut on the public markets isn\\'t indicative of how other newly listed companies may perform.\\n\\nTechGlobal, a formerly public company, was taken private by Vision Holdings in 2014. The well-established chip designer says it powers 85% of premium smartphones.\\n######################\\nOutput:\\n(\"entity\"<|>TECHGLOBAL<|>ORGANIZATION<|>TechGlobal is a stock now listed on the Global Exchange which powers 85% of premium smartphones)\\n##\\n(\"entity\"<|>VISION HOLDINGS<|>ORGANIZATION<|>Vision Holdings is a firm that previously owned TechGlobal)\\n##\\n(\"relationship\"<|>TECHGLOBAL<|>VISION HOLDINGS<|>Vision Holdings formerly owned TechGlobal from 2014 until present<|>5)\\n<|COMPLETE|>\\n\\n######################\\nExample 3:\\nEntity_types: ORGANIZATION,GEO,PERSON\\nText:\\nFive Aurelians jailed for 8 years in Firuzabad and widely regarded as hostages are on their way home to Aurelia.\\n\\nThe swap orchestrated by Quintara was finalized when $8bn of Firuzi funds were transferred to financial institutions in Krohaara, the capital of Quintara.\\n\\nThe exchange initiated in Firuzabad\\'s capital, Tiruzia, led to the four men and one woman, who are also Firuzi nationals, boarding a chartered flight to Krohaara.\\n\\nThey were welcomed by senior Aurelian officials and are now on their way to Aurelia\\'s capital, Cashion.\\n\\nThe Aurelians include 39-year-old businessman Samuel Namara, who has been held in Tiruzia\\'s Alhamia Prison, as well as journalist Durke Bataglani, 59, and environmentalist Meggie Tazbah, 53, who also holds Bratinas nationality.\\n######################\\nOutput:\\n(\"entity\"<|>FIRUZABAD<|>GEO<|>Firuzabad held Aurelians as hostages)\\n##\\n(\"entity\"<|>AURELIA<|>GEO<|>Country seeking to release hostages)\\n##\\n(\"entity\"<|>QUINTARA<|>GEO<|>Country that negotiated a swap of money in exchange for hostages)\\n##\\n##\\n(\"entity\"<|>TIRUZIA<|>GEO<|>Capital of Firuzabad where the Aurelians were being held)\\n##\\n(\"entity\"<|>KROHAARA<|>GEO<|>Capital city in Quintara)\\n##\\n(\"entity\"<|>CASHION<|>GEO<|>Capital city in Aurelia)\\n##\\n(\"entity\"<|>SAMUEL NAMARA<|>PERSON<|>Aurelian who spent time in Tiruzia\\'s Alhamia Prison)\\n##\\n(\"entity\"<|>ALHAMIA PRISON<|>GEO<|>Prison in Tiruzia)\\n##\\n(\"entity\"<|>DURKE BATAGLANI<|>PERSON<|>Aurelian journalist who was held hostage)\\n##\\n(\"entity\"<|>MEGGIE TAZBAH<|>PERSON<|>Bratinas national and environmentalist who was held hostage)\\n##\\n(\"relationship\"<|>FIRUZABAD<|>AURELIA<|>Firuzabad negotiated a hostage exchange with Aurelia<|>2)\\n##\\n(\"relationship\"<|>QUINTARA<|>AURELIA<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\\n##\\n(\"relationship\"<|>QUINTARA<|>FIRUZABAD<|>Quintara brokered the hostage exchange between Firuzabad and Aurelia<|>2)\\n##\\n(\"relationship\"<|>SAMUEL NAMARA<|>ALHAMIA PRISON<|>Samuel Namara was a prisoner at Alhamia prison<|>8)\\n##\\n(\"relationship\"<|>SAMUEL NAMARA<|>MEGGIE TAZBAH<|>Samuel Namara and Meggie Tazbah were exchanged in the same hostage release<|>2)\\n##\\n(\"relationship\"<|>SAMUEL NAMARA<|>DURKE BATAGLANI<|>Samuel Namara and Durke Bataglani were exchanged in the same hostage release<|>2)\\n##\\n(\"relationship\"<|>MEGGIE TAZBAH<|>DURKE BATAGLANI<|>Meggie Tazbah and Durke Bataglani were exchanged in the same hostage release<|>2)\\n##\\n(\"relationship\"<|>SAMUEL NAMARA<|>FIRUZABAD<|>Samuel Namara was a hostage in Firuzabad<|>2)\\n##\\n(\"relationship\"<|>MEGGIE TAZBAH<|>FIRUZABAD<|>Meggie Tazbah was a hostage in Firuzabad<|>2)\\n##\\n(\"relationship\"<|>DURKE BATAGLANI<|>FIRUZABAD<|>Durke Bataglani was a hostage in Firuzabad<|>2)\\n<|COMPLETE|>\\n\\n######################\\n-Real Data-\\n######################\\nEntity_types: organization,person,geo,event\\nText: Page 1:\\nFrom Local to Global: A Graph RAG Approach to Query-Focused Summarization: The use\\nof retrieval-augmented generation (RAG) to retrieve relevant informa- tion from an external\\nknowledge source enables large language models (LLMs) to answer questions over private\\nand/or previously unseen document collections. However, RAG fails on global questions\\ndirected at an entire text corpus, such as What are the main themes in the dataset?, since\\nthis is inherently a query- focused summarization (QFS) task, rather than an explicit retrieval\\ntask. Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical\\nRAG systems. To combine the strengths of these contrasting methods, we propose a Graph\\nRAG approach to question answering over private text corpora that scales with both the\\ngenerality of user questions and the quantity of source text to be in- dexed. Our approach\\nuses an LLM to build a graph-based text index in two stages: first to derive an entity\\nknowledge graph from the source documents, then to pre- generate community summaries\\nfor all groups of closely-related entities. Given a question, each community summary is used\\nto generate a partial response, before all partial responses are again summarized in a final\\nresponse to the user. For a class of global sensemaking questions over datasets in the 1\\nmillion token range, we show that Graph RAG leads to substantial improvements over a na\\nve RAG baseline for both the comprehensiveness and diversity of generated answers. An\\nopen-source, Python-based implementation of both global and local Graph RAG approaches\\nis forthcoming at https://aka.ms/graphrag.\\n######################\\nOutput:'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input Hello, world!\n",
      "input [HumanMessage(content='Hello, world!', additional_kwargs={}, response_metadata={})]\n",
      "input Hello, world!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"Hello! It's nice to meet you. Is there something I can help you with or would you like to chat?\", additional_kwargs={}, response_metadata={'model': 'llama3.1', 'created_at': '2024-09-24T11:39:53.454897Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 2133115250, 'load_duration': 32338792, 'prompt_eval_count': 14, 'prompt_eval_duration': 82287000, 'eval_count': 25, 'eval_duration': 2017446000}, id='run-e431b8ff-fe92-4405-a5ec-d472eec12106-0', usage_metadata={'input_tokens': 14, 'output_tokens': 25, 'total_tokens': 39})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "llm = ChatOpenAI(\n",
    "    api_key=\"ollama\",\n",
    "    base_url=\"http://ollama:11434/v1\",\n",
    "    model=\"llama3.1\",\n",
    "    # callbacks=[callback_handler],\n",
    ")\n",
    "llm.invoke(\"Hello, world!\")\n",
    "\n",
    "from langchain_ollama import ChatOllama\n",
    "llm = ChatOllama(\n",
    "    api_key=\"ollama\",\n",
    "    base_url=\"http://localhost:11434\",\n",
    "    model=\"llama3.1\",\n",
    "    # callbacks=[callback_handler],\n",
    ")\n",
    "llm.invoke(\"Hello, world!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# llm_model = os.environ[\"GRAPHRAG_LLM_MODEL\"]\n",
    "# embedding_model = os.environ[\"GRAPHRAG_EMBEDDING_MODEL\"]\n",
    "\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "llm = ChatOpenAI(\n",
    "    api_key=\"ollama\",\n",
    "    base_url=\"http://localhost:11434/v1\",\n",
    "    model=\"llama3.1\",\n",
    "    # callbacks=[callback_handler],\n",
    ")\n",
    "\n",
    "token_encoder = tiktoken.get_encoding(\"cl100k_base\")\n",
    "\n",
    "class OpenAICompatibleOllamaEmbedding:\n",
    "    def __init__(self, model: str):\n",
    "        self.model = model\n",
    "        \n",
    "\n",
    "    def __call__(self, prompt: str):\n",
    "        return ollama.embeddings(model=self.model, prompt=prompt)[\"embedding\"]\n",
    "\n",
    "    def embed(self, prompt: str):\n",
    "        return self(prompt=prompt)\n",
    "    \n",
    "    def embed_documents(self, texts: list[str]):\n",
    "        return [self(text) for text in texts]\n",
    "\n",
    "text_embedder = OpenAICompatibleOllamaEmbedding(model=\"nomic-embed-text\")\n",
    "\n",
    "# text_embedder = OpenAIEmbedding(\n",
    "#     api_key=api_key,\n",
    "#     api_base=None,\n",
    "#     api_type=OpenaiApiType.OpenAI,\n",
    "#     model=embedding_model,\n",
    "#     deployment_name=embedding_model,\n",
    "#     max_retries=20,\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create local search context builder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "context_builder = LocalSearchMixedContext(\n",
    "    community_reports=reports,\n",
    "    text_units=text_units,\n",
    "    entities=entities,\n",
    "    relationships=relationships,\n",
    "    # if you did not run covariates during indexing, set this to None\n",
    "    # covariates=covariates,\n",
    "    entity_text_embeddings=description_embedding_store,\n",
    "    embedding_vectorstore_key=EntityVectorStoreKey.ID,  # if the vectorstore uses entity title as ids, set this to EntityVectorStoreKey.TITLE\n",
    "    text_embedder=text_embedder,\n",
    "    token_encoder=token_encoder,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create local search engine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# text_unit_prop: proportion of context window dedicated to related text units\n",
    "# community_prop: proportion of context window dedicated to community reports.\n",
    "# The remaining proportion is dedicated to entities and relationships. Sum of text_unit_prop and community_prop should be <= 1\n",
    "# conversation_history_max_turns: maximum number of turns to include in the conversation history.\n",
    "# conversation_history_user_turns_only: if True, only include user queries in the conversation history.\n",
    "# top_k_mapped_entities: number of related entities to retrieve from the entity description embedding store.\n",
    "# top_k_relationships: control the number of out-of-network relationships to pull into the context window.\n",
    "# include_entity_rank: if True, include the entity rank in the entity table in the context window. Default entity rank = node degree.\n",
    "# include_relationship_weight: if True, include the relationship weight in the context window.\n",
    "# include_community_rank: if True, include the community rank in the context window.\n",
    "# return_candidate_context: if True, return a set of dataframes containing all candidate entity/relationship/covariate records that\n",
    "# could be relevant. Note that not all of these records will be included in the context window. The \"in_context\" column in these\n",
    "# dataframes indicates whether the record is included in the context window.\n",
    "# max_tokens: maximum number of tokens to use for the context window.\n",
    "\n",
    "\n",
    "local_context_params = {\n",
    "    \"text_unit_prop\": 0.5,\n",
    "    \"community_prop\": 0.1,\n",
    "    \"conversation_history_max_turns\": 5,\n",
    "    \"conversation_history_user_turns_only\": True,\n",
    "    \"top_k_mapped_entities\": 10,\n",
    "    \"top_k_relationships\": 10,\n",
    "    \"include_entity_rank\": True,\n",
    "    \"include_relationship_weight\": True,\n",
    "    \"include_community_rank\": False,\n",
    "    \"return_candidate_context\": False,\n",
    "    \"embedding_vectorstore_key\": EntityVectorStoreKey.ID,  # set this to EntityVectorStoreKey.TITLE if the vectorstore uses entity title as ids\n",
    "    \"max_tokens\": 12_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 5000)\n",
    "}\n",
    "\n",
    "llm_params = {\n",
    "    \"max_tokens\": 2_000,  # change this based on the token limit you have on your model (if you are using a model with 8k limit, a good setting could be 1000=1500)\n",
    "    \"temperature\": 0.0,\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "search_engine = LocalSearch(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    llm_params=llm_params,\n",
    "    context_builder_params=local_context_params,\n",
    "    response_type=\"multiple paragraphs\",  # free form text describing the response type and format, can be anything, e.g. prioritized list, single paragraph, multiple paragraphs, multiple-page report\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run local search on sample queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages {'role': 'system', 'content': '\\n---Role---\\n\\nYou are a helpful assistant responding to questions about data in the tables provided.\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\n\\n---Data tables---\\n\\n-----Reports-----\\nid|title|content\\n1|Graph RAG Community|\"# Graph RAG Community\\n\\nThe Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\\n\\n## Graph RAG is a graph-based approach to question answering\\n\\nThe Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\\n\\n## Model training is a crucial aspect of the Graph RAG community\\n\\nModel training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Evaluation metrics are essential for assessing the performance of question answering models\\n\\nThe Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\\n\\n## Graph RAG is implemented in Python\\n\\nThe Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Graph RAG has a strong focus on Microsoft\\n\\nThe Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company\\'s resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\\n\\n\\n-----Entities-----\\nid|entity|description|number of relationships\\n4|TEXT DATA|A dataset of text used for training and testing question answering models|2\\n17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\\n5|MODEL TRAINING|A process of training machine learning models on a dataset|2\\n0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\\n21|TEXT PROCESSING|The process of extracting information from text documents|1\\n2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\\n18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\\n15|INDEXING||1\\n19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\\n7|HTTPS://AKA.MS/GRAPHRAG||1\\n13|METHODS||1\\n24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\\n8|MS|Microsoft is the company behind the Graph RAG implementation|1\\n1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\\n23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\\n20|LLM||5\\n6|EVALUATION METRICS|A set of metrics used to evaluate the performance of question answering models|2\\n12|TEXT||1\\n16|SEARCHING||1\\n14|SYSTEMS||1\\n\\n\\n-----Relationships-----\\nid|source|target|description|weight|rank|links\\n1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|2\\n23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|4\\n2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|2\\n3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|2\\n4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|1\\n20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|4\\n26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|4\\n27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|4\\n6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|2\\n22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|2\\n21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|2\\n24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\\n0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|8\\n5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|8\\n7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|8\\n8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|8\\n9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|8\\n10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|8\\n11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|8\\n13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|8\\n17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|3\\n18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|3\\n19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|3\\n15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|2\\n16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|2\\n25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|1\\n\\n\\n-----Sources-----\\nid|text\\n0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\\n6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\\n4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\\n2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\\n\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\nAdd sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\\n'}\n",
      "input \n",
      "---Role---\n",
      "\n",
      "You are a helpful assistant responding to questions about data in the tables provided.\n",
      "\n",
      "\n",
      "---Goal---\n",
      "\n",
      "Generate a response of the target length and format that responds to the user's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\n",
      "\n",
      "If you don't know the answer, just say so. Do not make anything up.\n",
      "\n",
      "Points supported by data should list their data references as follows:\n",
      "\n",
      "\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\n",
      "\n",
      "Do not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
      "\n",
      "For example:\n",
      "\n",
      "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\n",
      "\n",
      "where 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n",
      "\n",
      "Do not include information where the supporting evidence for it is not provided.\n",
      "\n",
      "\n",
      "---Target response length and format---\n",
      "\n",
      "multiple paragraphs\n",
      "\n",
      "\n",
      "---Data tables---\n",
      "\n",
      "-----Reports-----\n",
      "id|title|content\n",
      "1|Graph RAG Community|\"# Graph RAG Community\n",
      "\n",
      "The Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\n",
      "\n",
      "## Graph RAG is a graph-based approach to question answering\n",
      "\n",
      "The Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\n",
      "\n",
      "## Model training is a crucial aspect of the Graph RAG community\n",
      "\n",
      "Model training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\n",
      "\n",
      "## Evaluation metrics are essential for assessing the performance of question answering models\n",
      "\n",
      "The Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\n",
      "\n",
      "## Graph RAG is implemented in Python\n",
      "\n",
      "The Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\n",
      "\n",
      "## Graph RAG has a strong focus on Microsoft\n",
      "\n",
      "The Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company's resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\n",
      "\n",
      "\n",
      "-----Entities-----\n",
      "id|entity|description|number of relationships\n",
      "4|TEXT DATA|A dataset of text used for training and testing question answering models|2\n",
      "17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\n",
      "5|MODEL TRAINING|A process of training machine learning models on a dataset|2\n",
      "0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\n",
      "21|TEXT PROCESSING|The process of extracting information from text documents|1\n",
      "2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\n",
      "18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\n",
      "15|INDEXING||1\n",
      "19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\n",
      "7|HTTPS://AKA.MS/GRAPHRAG||1\n",
      "13|METHODS||1\n",
      "24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\n",
      "8|MS|Microsoft is the company behind the Graph RAG implementation|1\n",
      "1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\n",
      "23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\n",
      "20|LLM||5\n",
      "6|EVALUATION METRICS|A set of metrics used to evaluate the performance of question answering models|2\n",
      "12|TEXT||1\n",
      "16|SEARCHING||1\n",
      "14|SYSTEMS||1\n",
      "\n",
      "\n",
      "-----Relationships-----\n",
      "id|source|target|description|weight|rank|links\n",
      "1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|2\n",
      "23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|4\n",
      "2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|2\n",
      "3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|2\n",
      "4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|1\n",
      "20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|4\n",
      "26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|4\n",
      "27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|4\n",
      "6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|2\n",
      "22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|2\n",
      "21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|2\n",
      "24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\n",
      "0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|8\n",
      "5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|8\n",
      "7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|8\n",
      "8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|8\n",
      "9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|8\n",
      "10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|8\n",
      "11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|8\n",
      "13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|8\n",
      "17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|3\n",
      "18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|3\n",
      "19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|3\n",
      "15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|2\n",
      "16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|2\n",
      "25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|1\n",
      "\n",
      "\n",
      "-----Sources-----\n",
      "id|text\n",
      "0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\n",
      "6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\n",
      "4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\n",
      "2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\n",
      "\n",
      "\n",
      "\n",
      "---Goal---\n",
      "\n",
      "Generate a response of the target length and format that responds to the user's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\n",
      "\n",
      "If you don't know the answer, just say so. Do not make anything up.\n",
      "\n",
      "Points supported by data should list their data references as follows:\n",
      "\n",
      "\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\n",
      "\n",
      "Do not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
      "\n",
      "For example:\n",
      "\n",
      "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\n",
      "\n",
      "where 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n",
      "\n",
      "Do not include information where the supporting evidence for it is not provided.\n",
      "\n",
      "\n",
      "---Target response length and format---\n",
      "\n",
      "multiple paragraphs\n",
      "\n",
      "Add sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\n",
      "\n",
      "payload {'messages': [{'content': '\\n---Role---\\n\\nYou are a helpful assistant responding to questions about data in the tables provided.\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\n\\n---Data tables---\\n\\n-----Reports-----\\nid|title|content\\n1|Graph RAG Community|\"# Graph RAG Community\\n\\nThe Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\\n\\n## Graph RAG is a graph-based approach to question answering\\n\\nThe Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\\n\\n## Model training is a crucial aspect of the Graph RAG community\\n\\nModel training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Evaluation metrics are essential for assessing the performance of question answering models\\n\\nThe Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\\n\\n## Graph RAG is implemented in Python\\n\\nThe Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Graph RAG has a strong focus on Microsoft\\n\\nThe Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company\\'s resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\\n\\n\\n-----Entities-----\\nid|entity|description|number of relationships\\n4|TEXT DATA|A dataset of text used for training and testing question answering models|2\\n17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\\n5|MODEL TRAINING|A process of training machine learning models on a dataset|2\\n0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\\n21|TEXT PROCESSING|The process of extracting information from text documents|1\\n2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\\n18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\\n15|INDEXING||1\\n19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\\n7|HTTPS://AKA.MS/GRAPHRAG||1\\n13|METHODS||1\\n24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\\n8|MS|Microsoft is the company behind the Graph RAG implementation|1\\n1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\\n23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\\n20|LLM||5\\n6|EVALUATION METRICS|A set of metrics used to evaluate the performance of question answering models|2\\n12|TEXT||1\\n16|SEARCHING||1\\n14|SYSTEMS||1\\n\\n\\n-----Relationships-----\\nid|source|target|description|weight|rank|links\\n1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|2\\n23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|4\\n2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|2\\n3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|2\\n4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|1\\n20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|4\\n26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|4\\n27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|4\\n6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|2\\n22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|2\\n21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|2\\n24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\\n0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|8\\n5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|8\\n7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|8\\n8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|8\\n9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|8\\n10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|8\\n11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|8\\n13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|8\\n17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|3\\n18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|3\\n19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|3\\n15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|2\\n16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|2\\n25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|1\\n\\n\\n-----Sources-----\\nid|text\\n0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\\n6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\\n4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\\n2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\\n\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\nAdd sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\\n', 'role': 'user'}], 'model': 'llama3.1', 'stream': False, 'n': 1, 'temperature': 0.0, 'streaming': True, 'max_tokens': 2000}\n",
      "messages {'role': 'user', 'content': 'Tell me about Ishita Mann'}\n",
      "input Tell me about Ishita Mann\n",
      "payload {'messages': [{'content': 'Tell me about Ishita Mann', 'role': 'user'}], 'model': 'llama3.1', 'stream': False, 'n': 1, 'temperature': 0.0, 'streaming': True, 'max_tokens': 2000}\n",
      "generations=[[ChatGeneration(text='**Graph RAG Approach: A Scalable Solution for Question Answering over Private Text Corpora**\\n=====================================================================================\\n\\nThe Graph RAG approach is a novel method for answering user questions by indexing private text corpora, leveraging the strengths of both contrasting methods [0]. This approach scales with both the generality of user questions and the quantity of source text to be indexed [0].\\n\\n**Key Components of the Graph RAG Approach**\\n------------------------------------------\\n\\nThe Graph RAG approach involves two stages:\\n\\n1. **Entity Knowledge Graph**: An LLM is used to build a graph-based text index by deriving an entity knowledge graph from the source documents [25]. This stage enables the identification of closely-related entities.\\n2. **Community Summaries**: The graph-based text index is then used to pre-generate community summaries for all groups of closely-related entities [21, 22].\\n\\n**Advantages over Prior QFS Methods**\\n--------------------------------------\\n\\nPrior QFS methods fail to scale to the quantities of text indexed by typical RAG systems, making searching difficult [16]. In contrast, the Graph RAG approach is designed to handle large amounts of text and user questions.\\n\\n**Implementation and Availability**\\n-------------------------------\\n\\nAn open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag [2].\\n\\n**Conclusion**\\n----------\\n\\nThe Graph RAG approach offers a scalable solution for question answering over private text corpora. By leveraging the strengths of contrasting methods and addressing the limitations of prior QFS methods, this approach has the potential to revolutionize the way we answer user questions.\\n\\nNote: The above response is based on the provided data tables and does not include any information that is not supported by the evidence.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='**Graph RAG Approach: A Scalable Solution for Question Answering over Private Text Corpora**\\n=====================================================================================\\n\\nThe Graph RAG approach is a novel method for answering user questions by indexing private text corpora, leveraging the strengths of both contrasting methods [0]. This approach scales with both the generality of user questions and the quantity of source text to be indexed [0].\\n\\n**Key Components of the Graph RAG Approach**\\n------------------------------------------\\n\\nThe Graph RAG approach involves two stages:\\n\\n1. **Entity Knowledge Graph**: An LLM is used to build a graph-based text index by deriving an entity knowledge graph from the source documents [25]. This stage enables the identification of closely-related entities.\\n2. **Community Summaries**: The graph-based text index is then used to pre-generate community summaries for all groups of closely-related entities [21, 22].\\n\\n**Advantages over Prior QFS Methods**\\n--------------------------------------\\n\\nPrior QFS methods fail to scale to the quantities of text indexed by typical RAG systems, making searching difficult [16]. In contrast, the Graph RAG approach is designed to handle large amounts of text and user questions.\\n\\n**Implementation and Availability**\\n-------------------------------\\n\\nAn open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag [2].\\n\\n**Conclusion**\\n----------\\n\\nThe Graph RAG approach offers a scalable solution for question answering over private text corpora. By leveraging the strengths of contrasting methods and addressing the limitations of prior QFS methods, this approach has the potential to revolutionize the way we answer user questions.\\n\\nNote: The above response is based on the provided data tables and does not include any information that is not supported by the evidence.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 345, 'prompt_tokens': 1026, 'total_tokens': 1371, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-5df49672-0d8f-4b06-9295-e6945625e01a-0', usage_metadata={'input_tokens': 1026, 'output_tokens': 345, 'total_tokens': 1371}))], [ChatGeneration(text=\"I couldn't find any notable or well-known information on a person named Ishita Mann. It's possible that she is a private individual, not a public figure, or may not have a significant online presence.\\n\\nHowever, I can suggest some possibilities:\\n\\n1. **Indian name**: Ishita is a common Indian name, and there might be many people with this name in India.\\n2. **Local or regional significance**: Ishita Mann might be a notable person in her local community or region, but not well-known outside of it.\\n3. **Private individual**: As mentioned earlier, she could be a private individual who doesn't have an online presence or hasn't gained significant public attention.\\n\\nIf you could provide more context or information about Ishita Mann (e.g., profession, location, interests), I might be able to help you better!\", generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content=\"I couldn't find any notable or well-known information on a person named Ishita Mann. It's possible that she is a private individual, not a public figure, or may not have a significant online presence.\\n\\nHowever, I can suggest some possibilities:\\n\\n1. **Indian name**: Ishita is a common Indian name, and there might be many people with this name in India.\\n2. **Local or regional significance**: Ishita Mann might be a notable person in her local community or region, but not well-known outside of it.\\n3. **Private individual**: As mentioned earlier, she could be a private individual who doesn't have an online presence or hasn't gained significant public attention.\\n\\nIf you could provide more context or information about Ishita Mann (e.g., profession, location, interests), I might be able to help you better!\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 170, 'prompt_tokens': 16, 'total_tokens': 186, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-e2e009c0-0f68-4d07-a7a7-bc355a973347-0', usage_metadata={'input_tokens': 16, 'output_tokens': 170, 'total_tokens': 186}))]] llm_output={'token_usage': {'completion_tokens': 515, 'prompt_tokens': 1042, 'total_tokens': 1557, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama'} run=[RunInfo(run_id=UUID('5df49672-0d8f-4b06-9295-e6945625e01a')), RunInfo(run_id=UUID('e2e009c0-0f68-4d07-a7a7-bc355a973347'))] type='LLMResult'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:357: UserWarning: Unexpected type for token usage: <class 'NoneType'>\n",
      "  warnings.warn(f\"Unexpected type for token usage: {type(new_usage)}\")\n"
     ]
    }
   ],
   "source": [
    "result = await search_engine.asearch(\"Tell me about Ishita Mann\")\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages {'role': 'system', 'content': '\\n---Role---\\n\\nYou are a helpful assistant responding to questions about data in the tables provided.\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\n\\n---Data tables---\\n\\n-----Reports-----\\nid|title|content\\n1|Graph RAG Community|\"# Graph RAG Community\\n\\nThe Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\\n\\n## Graph RAG is a graph-based approach to question answering\\n\\nThe Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\\n\\n## Model training is a crucial aspect of the Graph RAG community\\n\\nModel training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Evaluation metrics are essential for assessing the performance of question answering models\\n\\nThe Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\\n\\n## Graph RAG is implemented in Python\\n\\nThe Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Graph RAG has a strong focus on Microsoft\\n\\nThe Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company\\'s resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\\n\\n\\n-----Entities-----\\nid|entity|description|number of relationships\\n3|GRAPH RAG||9\\n2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\\n8|MS|Microsoft is the company behind the Graph RAG implementation|1\\n7|HTTPS://AKA.MS/GRAPHRAG||1\\n0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\\n17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\\n11|RAG SYSTEMS||4\\n18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\\n19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\\n22|ENTITY KNOWLEDGE GRAPH||1\\n4|TEXT DATA|A dataset of text used for training and testing question answering models|2\\n1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\\n15|INDEXING||1\\n13|METHODS||1\\n9|PYTHON||1\\n24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\\n12|TEXT||1\\n16|SEARCHING||1\\n23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\\n5|MODEL TRAINING|A process of training machine learning models on a dataset|2\\n\\n\\n-----Relationships-----\\nid|source|target|description|weight|rank|links\\n0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|1\\n5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|3\\n7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|1\\n8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|2\\n9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|2\\n11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|1\\n12|GRAPH RAG|PYTHON|Graph RAG is implemented in Python|8.0|10|1\\n13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|1\\n1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|3\\n2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|2\\n3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|2\\n6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|3\\n17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|1\\n19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|1\\n22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|2\\n21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|2\\n23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|5\\n20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|5\\n25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|5\\n26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|5\\n27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|5\\n14|QFS|RAG SYSTEMS|QFS methods fail to scale to the quantities of text indexed by typical RAG systems|3.0|7|3\\n15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|3\\n16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|3\\n10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|2\\n4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|2\\n18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|1\\n24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\\n\\n\\n-----Sources-----\\nid|text\\n0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\\n2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\\n6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\\n4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\\n\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\nAdd sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\\n'}\n",
      "input \n",
      "---Role---\n",
      "\n",
      "You are a helpful assistant responding to questions about data in the tables provided.\n",
      "\n",
      "\n",
      "---Goal---\n",
      "\n",
      "Generate a response of the target length and format that responds to the user's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\n",
      "\n",
      "If you don't know the answer, just say so. Do not make anything up.\n",
      "\n",
      "Points supported by data should list their data references as follows:\n",
      "\n",
      "\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\n",
      "\n",
      "Do not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
      "\n",
      "For example:\n",
      "\n",
      "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\n",
      "\n",
      "where 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n",
      "\n",
      "Do not include information where the supporting evidence for it is not provided.\n",
      "\n",
      "\n",
      "---Target response length and format---\n",
      "\n",
      "multiple paragraphs\n",
      "\n",
      "\n",
      "---Data tables---\n",
      "\n",
      "-----Reports-----\n",
      "id|title|content\n",
      "1|Graph RAG Community|\"# Graph RAG Community\n",
      "\n",
      "The Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\n",
      "\n",
      "## Graph RAG is a graph-based approach to question answering\n",
      "\n",
      "The Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\n",
      "\n",
      "## Model training is a crucial aspect of the Graph RAG community\n",
      "\n",
      "Model training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\n",
      "\n",
      "## Evaluation metrics are essential for assessing the performance of question answering models\n",
      "\n",
      "The Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\n",
      "\n",
      "## Graph RAG is implemented in Python\n",
      "\n",
      "The Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\n",
      "\n",
      "## Graph RAG has a strong focus on Microsoft\n",
      "\n",
      "The Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company's resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\n",
      "\n",
      "\n",
      "-----Entities-----\n",
      "id|entity|description|number of relationships\n",
      "3|GRAPH RAG||9\n",
      "2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\n",
      "8|MS|Microsoft is the company behind the Graph RAG implementation|1\n",
      "7|HTTPS://AKA.MS/GRAPHRAG||1\n",
      "0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\n",
      "17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\n",
      "11|RAG SYSTEMS||4\n",
      "18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\n",
      "19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\n",
      "22|ENTITY KNOWLEDGE GRAPH||1\n",
      "4|TEXT DATA|A dataset of text used for training and testing question answering models|2\n",
      "1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\n",
      "15|INDEXING||1\n",
      "13|METHODS||1\n",
      "9|PYTHON||1\n",
      "24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\n",
      "12|TEXT||1\n",
      "16|SEARCHING||1\n",
      "23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\n",
      "5|MODEL TRAINING|A process of training machine learning models on a dataset|2\n",
      "\n",
      "\n",
      "-----Relationships-----\n",
      "id|source|target|description|weight|rank|links\n",
      "0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|1\n",
      "5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|3\n",
      "7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|1\n",
      "8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|2\n",
      "9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|2\n",
      "11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|1\n",
      "12|GRAPH RAG|PYTHON|Graph RAG is implemented in Python|8.0|10|1\n",
      "13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|1\n",
      "1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|3\n",
      "2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|2\n",
      "3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|2\n",
      "6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|3\n",
      "17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|1\n",
      "19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|1\n",
      "22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|2\n",
      "21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|2\n",
      "23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|5\n",
      "20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|5\n",
      "25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|5\n",
      "26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|5\n",
      "27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|5\n",
      "14|QFS|RAG SYSTEMS|QFS methods fail to scale to the quantities of text indexed by typical RAG systems|3.0|7|3\n",
      "15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|3\n",
      "16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|3\n",
      "10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|2\n",
      "4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|2\n",
      "18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|1\n",
      "24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\n",
      "\n",
      "\n",
      "-----Sources-----\n",
      "id|text\n",
      "0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\n",
      "2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\n",
      "6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\n",
      "4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\n",
      "\n",
      "\n",
      "\n",
      "---Goal---\n",
      "\n",
      "Generate a response of the target length and format that responds to the user's question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\n",
      "\n",
      "If you don't know the answer, just say so. Do not make anything up.\n",
      "\n",
      "Points supported by data should list their data references as follows:\n",
      "\n",
      "\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\n",
      "\n",
      "Do not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\n",
      "\n",
      "For example:\n",
      "\n",
      "\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\n",
      "\n",
      "where 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\n",
      "\n",
      "Do not include information where the supporting evidence for it is not provided.\n",
      "\n",
      "\n",
      "---Target response length and format---\n",
      "\n",
      "multiple paragraphs\n",
      "\n",
      "Add sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\n",
      "\n",
      "payload {'messages': [{'content': '\\n---Role---\\n\\nYou are a helpful assistant responding to questions about data in the tables provided.\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\n\\n---Data tables---\\n\\n-----Reports-----\\nid|title|content\\n1|Graph RAG Community|\"# Graph RAG Community\\n\\nThe Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\\n\\n## Graph RAG is a graph-based approach to question answering\\n\\nThe Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\\n\\n## Model training is a crucial aspect of the Graph RAG community\\n\\nModel training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Evaluation metrics are essential for assessing the performance of question answering models\\n\\nThe Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\\n\\n## Graph RAG is implemented in Python\\n\\nThe Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Graph RAG has a strong focus on Microsoft\\n\\nThe Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company\\'s resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\\n\\n\\n-----Entities-----\\nid|entity|description|number of relationships\\n3|GRAPH RAG||9\\n2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\\n8|MS|Microsoft is the company behind the Graph RAG implementation|1\\n7|HTTPS://AKA.MS/GRAPHRAG||1\\n0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\\n17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\\n11|RAG SYSTEMS||4\\n18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\\n19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\\n22|ENTITY KNOWLEDGE GRAPH||1\\n4|TEXT DATA|A dataset of text used for training and testing question answering models|2\\n1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\\n15|INDEXING||1\\n13|METHODS||1\\n9|PYTHON||1\\n24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\\n12|TEXT||1\\n16|SEARCHING||1\\n23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\\n5|MODEL TRAINING|A process of training machine learning models on a dataset|2\\n\\n\\n-----Relationships-----\\nid|source|target|description|weight|rank|links\\n0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|1\\n5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|3\\n7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|1\\n8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|2\\n9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|2\\n11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|1\\n12|GRAPH RAG|PYTHON|Graph RAG is implemented in Python|8.0|10|1\\n13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|1\\n1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|3\\n2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|2\\n3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|2\\n6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|3\\n17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|1\\n19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|1\\n22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|2\\n21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|2\\n23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|5\\n20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|5\\n25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|5\\n26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|5\\n27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|5\\n14|QFS|RAG SYSTEMS|QFS methods fail to scale to the quantities of text indexed by typical RAG systems|3.0|7|3\\n15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|3\\n16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|3\\n10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|2\\n4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|2\\n18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|1\\n24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\\n\\n\\n-----Sources-----\\nid|text\\n0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\\n2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\\n6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\\n4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\\n\\n\\n\\n---Goal---\\n\\nGenerate a response of the target length and format that responds to the user\\'s question, summarizing all information in the input data tables appropriate for the response length and format, and incorporating any relevant general knowledge.\\n\\nIf you don\\'t know the answer, just say so. Do not make anything up.\\n\\nPoints supported by data should list their data references as follows:\\n\\n\"This is an example sentence supported by multiple data references [Data: <dataset name> (record ids); <dataset name> (record ids)].\"\\n\\nDo not list more than 5 record ids in a single reference. Instead, list the top 5 most relevant record ids and add \"+more\" to indicate that there are more.\\n\\nFor example:\\n\\n\"Person X is the owner of Company Y and subject to many allegations of wrongdoing [Data: Sources (15, 16), Reports (1), Entities (5, 7); Relationships (23); Claims (2, 7, 34, 46, 64, +more)].\"\\n\\nwhere 15, 16, 1, 5, 7, 23, 2, 7, 34, 46, and 64 represent the id (not the index) of the relevant data record.\\n\\nDo not include information where the supporting evidence for it is not provided.\\n\\n\\n---Target response length and format---\\n\\nmultiple paragraphs\\n\\nAdd sections and commentary to the response as appropriate for the length and format. Style the response in markdown.\\n', 'role': 'user'}], 'model': 'llama3.1', 'stream': False, 'n': 1, 'temperature': 0.0, 'streaming': True, 'max_tokens': 2000}\n",
      "messages {'role': 'user', 'content': 'what is the usecase of Graph RAG'}\n",
      "input what is the usecase of Graph RAG\n",
      "payload {'messages': [{'content': 'what is the usecase of Graph RAG', 'role': 'user'}], 'model': 'llama3.1', 'stream': False, 'n': 1, 'temperature': 0.0, 'streaming': True, 'max_tokens': 2000}\n",
      "generations=[[ChatGeneration(text='**Question Answering over Private Text Corpora: A Graph RAG Approach**\\n====================================================================\\n\\nThe Graph RAG approach is a novel method for indexing private text corpora using large language models (LLMs) [Data: 0, 6]. This approach scales with both the generality of user questions and the quantity of source text to be indexed, making it an attractive solution for question answering over large datasets.\\n\\n**Key Components of the Graph RAG Approach**\\n------------------------------------------\\n\\nThe Graph RAG approach involves two primary stages:\\n\\n1. **Entity Knowledge Graph Construction**: The LLM is used to derive an entity knowledge graph from the source documents [Data: 23]. This stage involves processing the source documents using various techniques, including text processing and analysis [Data: 24].\\n2. **Community Summaries Generation**: The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities [Data: 22, 21].\\n\\n**Advantages over Traditional QFS Methods**\\n------------------------------------------\\n\\nPrior methods for querying and searching large amounts of text (QFS) fail to scale to the quantities of text indexed by typical RAG systems [Data: 14, 15, 16]. In contrast, the Graph RAG approach is designed to handle large datasets and provide accurate question answering results.\\n\\n**Evaluation Metrics**\\n-------------------\\n\\nThe Graph RAG approach is evaluated using a set of evaluation metrics, including those used for question answering models [Data: 10, 4].\\n\\n**Conclusion**\\n----------\\n\\nIn conclusion, the Graph RAG approach offers a scalable solution for indexing private text corpora and providing accurate question answering results. By leveraging LLMs and graph-based indexing techniques, this approach can handle large datasets and provide valuable insights to users.\\n\\nNote: The above response is based on the provided data tables and does not include any information that is not supported by the evidence.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='**Question Answering over Private Text Corpora: A Graph RAG Approach**\\n====================================================================\\n\\nThe Graph RAG approach is a novel method for indexing private text corpora using large language models (LLMs) [Data: 0, 6]. This approach scales with both the generality of user questions and the quantity of source text to be indexed, making it an attractive solution for question answering over large datasets.\\n\\n**Key Components of the Graph RAG Approach**\\n------------------------------------------\\n\\nThe Graph RAG approach involves two primary stages:\\n\\n1. **Entity Knowledge Graph Construction**: The LLM is used to derive an entity knowledge graph from the source documents [Data: 23]. This stage involves processing the source documents using various techniques, including text processing and analysis [Data: 24].\\n2. **Community Summaries Generation**: The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities [Data: 22, 21].\\n\\n**Advantages over Traditional QFS Methods**\\n------------------------------------------\\n\\nPrior methods for querying and searching large amounts of text (QFS) fail to scale to the quantities of text indexed by typical RAG systems [Data: 14, 15, 16]. In contrast, the Graph RAG approach is designed to handle large datasets and provide accurate question answering results.\\n\\n**Evaluation Metrics**\\n-------------------\\n\\nThe Graph RAG approach is evaluated using a set of evaluation metrics, including those used for question answering models [Data: 10, 4].\\n\\n**Conclusion**\\n----------\\n\\nIn conclusion, the Graph RAG approach offers a scalable solution for indexing private text corpora and providing accurate question answering results. By leveraging LLMs and graph-based indexing techniques, this approach can handle large datasets and provide valuable insights to users.\\n\\nNote: The above response is based on the provided data tables and does not include any information that is not supported by the evidence.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 382, 'prompt_tokens': 1026, 'total_tokens': 1408, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-e81cc083-44c8-43ca-9e77-c80f13e63e77-0', usage_metadata={'input_tokens': 1026, 'output_tokens': 382, 'total_tokens': 1408}))], [ChatGeneration(text=\"Graph Random Access Memory (RAG) is a technique used in graph neural networks to efficiently store and retrieve graph data. Here are some common use cases for Graph RAG:\\n\\n1. **Graph-based recommendation systems**: In recommendation systems, users are often connected by their interactions or preferences. Graph RAG can be used to efficiently store and query these user-item interactions, enabling personalized recommendations.\\n2. **Knowledge graph embeddings**: Knowledge graphs represent entities and their relationships as nodes and edges in a graph. Graph RAG can be used to efficiently compute and store knowledge graph embeddings, which are useful for tasks like entity disambiguation and question answering.\\n3. **Graph-based clustering**: Graph RAG can be used to efficiently cluster nodes in a graph based on their structural similarity. This is useful for tasks like community detection in social networks or identifying clusters of similar products.\\n4. **Graph neural network (GNN) acceleration**: Graph RAG can be used to accelerate the computation of GNNs by storing and retrieving graph data in a more efficient manner, reducing the number of memory accesses and improving overall performance.\\n5. **Graph-based anomaly detection**: Graph RAG can be used to efficiently store and query graph data for anomaly detection tasks, such as identifying unusual patterns or outliers in a graph.\\n6. **Graph-based clustering with node attributes**: In some cases, nodes in a graph have additional attributes that need to be considered during clustering. Graph RAG can be used to efficiently store and retrieve these attributes while performing clustering.\\n7. **Graph-based recommendation systems with item attributes**: Similar to the previous point, Graph RAG can be used to efficiently store and query item attributes in addition to user-item interactions, enabling more accurate recommendations.\\n\\nSome of the benefits of using Graph RAG include:\\n\\n* **Improved memory efficiency**: By storing graph data in a compact and structured manner, Graph RAG reduces memory usage and improves overall performance.\\n* **Faster querying**: Graph RAG enables fast querying and retrieval of graph data, making it suitable for large-scale applications.\\n* **Scalability**: Graph RAG can handle large graphs with millions or even billions of nodes and edges, making it a scalable solution for many use cases.\\n\\nSome popular libraries that implement Graph RAG include:\\n\\n* PyTorch Geometric (PyG)\\n* TensorFlow Graph Rag\\n* GraphRAG (a standalone library)\\n\\nKeep in mind that the specific use case and implementation details may vary depending on the problem you're trying to solve.\", generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content=\"Graph Random Access Memory (RAG) is a technique used in graph neural networks to efficiently store and retrieve graph data. Here are some common use cases for Graph RAG:\\n\\n1. **Graph-based recommendation systems**: In recommendation systems, users are often connected by their interactions or preferences. Graph RAG can be used to efficiently store and query these user-item interactions, enabling personalized recommendations.\\n2. **Knowledge graph embeddings**: Knowledge graphs represent entities and their relationships as nodes and edges in a graph. Graph RAG can be used to efficiently compute and store knowledge graph embeddings, which are useful for tasks like entity disambiguation and question answering.\\n3. **Graph-based clustering**: Graph RAG can be used to efficiently cluster nodes in a graph based on their structural similarity. This is useful for tasks like community detection in social networks or identifying clusters of similar products.\\n4. **Graph neural network (GNN) acceleration**: Graph RAG can be used to accelerate the computation of GNNs by storing and retrieving graph data in a more efficient manner, reducing the number of memory accesses and improving overall performance.\\n5. **Graph-based anomaly detection**: Graph RAG can be used to efficiently store and query graph data for anomaly detection tasks, such as identifying unusual patterns or outliers in a graph.\\n6. **Graph-based clustering with node attributes**: In some cases, nodes in a graph have additional attributes that need to be considered during clustering. Graph RAG can be used to efficiently store and retrieve these attributes while performing clustering.\\n7. **Graph-based recommendation systems with item attributes**: Similar to the previous point, Graph RAG can be used to efficiently store and query item attributes in addition to user-item interactions, enabling more accurate recommendations.\\n\\nSome of the benefits of using Graph RAG include:\\n\\n* **Improved memory efficiency**: By storing graph data in a compact and structured manner, Graph RAG reduces memory usage and improves overall performance.\\n* **Faster querying**: Graph RAG enables fast querying and retrieval of graph data, making it suitable for large-scale applications.\\n* **Scalability**: Graph RAG can handle large graphs with millions or even billions of nodes and edges, making it a scalable solution for many use cases.\\n\\nSome popular libraries that implement Graph RAG include:\\n\\n* PyTorch Geometric (PyG)\\n* TensorFlow Graph Rag\\n* GraphRAG (a standalone library)\\n\\nKeep in mind that the specific use case and implementation details may vary depending on the problem you're trying to solve.\", additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 503, 'prompt_tokens': 19, 'total_tokens': 522, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-6a3ec287-8e25-4b4a-8f39-b93fc7c860d0-0', usage_metadata={'input_tokens': 19, 'output_tokens': 503, 'total_tokens': 522}))]] llm_output={'token_usage': {'completion_tokens': 885, 'prompt_tokens': 1045, 'total_tokens': 1930, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama'} run=[RunInfo(run_id=UUID('e81cc083-44c8-43ca-9e77-c80f13e63e77')), RunInfo(run_id=UUID('6a3ec287-8e25-4b4a-8f39-b93fc7c860d0'))] type='LLMResult'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:357: UserWarning: Unexpected type for token usage: <class 'NoneType'>\n",
      "  warnings.warn(f\"Unexpected type for token usage: {type(new_usage)}\")\n"
     ]
    }
   ],
   "source": [
    "question = \"what is the usecase of Graph RAG\"\n",
    "result = await search_engine.asearch(question)\n",
    "print(result.response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Inspecting the context data used to generate the response"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>entity</th>\n",
       "      <th>description</th>\n",
       "      <th>number of relationships</th>\n",
       "      <th>in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>4</td>\n",
       "      <td>TEXT DATA</td>\n",
       "      <td>A dataset of text used for training and testin...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>18</td>\n",
       "      <td>SOURCE DOCUMENTS</td>\n",
       "      <td>The original texts that are being processed to...</td>\n",
       "      <td>3</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>USER QUESTIONS</td>\n",
       "      <td>Questions asked by users to be answered by the...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>8</td>\n",
       "      <td>MS</td>\n",
       "      <td>Microsoft is the company behind the Graph RAG ...</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>17</td>\n",
       "      <td>GRAPH-BASED TEXT INDEX</td>\n",
       "      <td>A graph-based index of entities and relationsh...</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   id                  entity  \\\n",
       "0   4               TEXT DATA   \n",
       "1  18        SOURCE DOCUMENTS   \n",
       "2   2          USER QUESTIONS   \n",
       "3   8                      MS   \n",
       "4  17  GRAPH-BASED TEXT INDEX   \n",
       "\n",
       "                                         description number of relationships  \\\n",
       "0  A dataset of text used for training and testin...                       2   \n",
       "1  The original texts that are being processed to...                       3   \n",
       "2  Questions asked by users to be answered by the...                       2   \n",
       "3  Microsoft is the company behind the Graph RAG ...                       1   \n",
       "4  A graph-based index of entities and relationsh...                       2   \n",
       "\n",
       "   in_context  \n",
       "0        True  \n",
       "1        True  \n",
       "2        True  \n",
       "3        True  \n",
       "4        True  "
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.context_data[\"entities\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>source</th>\n",
       "      <th>target</th>\n",
       "      <th>description</th>\n",
       "      <th>weight</th>\n",
       "      <th>rank</th>\n",
       "      <th>links</th>\n",
       "      <th>in_context</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>PRIVATE TEXT CORPORA</td>\n",
       "      <td>Question answering is used to index private te...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>8</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>TEXT DATA</td>\n",
       "      <td>Question answering models are trained on a lar...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>MODEL TRAINING</td>\n",
       "      <td>Question answering models are trained using th...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>QUESTION ANSWERING</td>\n",
       "      <td>EVALUATION METRICS</td>\n",
       "      <td>Question answering models are evaluated using ...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>PRIVATE TEXT CORPORA</td>\n",
       "      <td>USER QUESTIONS</td>\n",
       "      <td>User questions are answered by indexing privat...</td>\n",
       "      <td>3.0</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                source                target  \\\n",
       "0  1    QUESTION ANSWERING  PRIVATE TEXT CORPORA   \n",
       "1  2    QUESTION ANSWERING             TEXT DATA   \n",
       "2  3    QUESTION ANSWERING        MODEL TRAINING   \n",
       "3  4    QUESTION ANSWERING    EVALUATION METRICS   \n",
       "4  6  PRIVATE TEXT CORPORA        USER QUESTIONS   \n",
       "\n",
       "                                         description weight rank links  \\\n",
       "0  Question answering is used to index private te...    4.0    8     2   \n",
       "1  Question answering models are trained on a lar...    3.0    7     1   \n",
       "2  Question answering models are trained using th...    2.0    7     1   \n",
       "3  Question answering models are evaluated using ...    2.0    7     1   \n",
       "4  User questions are answered by indexing privat...    3.0    5     2   \n",
       "\n",
       "   in_context  \n",
       "0        True  \n",
       "1        True  \n",
       "2        True  \n",
       "3        True  \n",
       "4        True  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.context_data[\"relationships\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>content</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Graph RAG Community</td>\n",
       "      <td># Graph RAG Community\\n\\nThe Graph RAG communi...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                title                                            content\n",
       "0  1  Graph RAG Community  # Graph RAG Community\\n\\nThe Graph RAG communi..."
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.context_data[\"reports\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>To combine the strengths of these contrasting ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>6</td>\n",
       "      <td>Our approach uses an LLM to build a graph-base...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>An open-source, Python-based implementation of...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Prior QFS methods, meanwhile, fail to scale to...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  id                                               text\n",
       "0  0  To combine the strengths of these contrasting ...\n",
       "1  6  Our approach uses an LLM to build a graph-base...\n",
       "2  2  An open-source, Python-based implementation of...\n",
       "3  4  Prior QFS methods, meanwhile, fail to scale to..."
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.context_data[\"sources\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "if \"claims\" in result.context_data:\n",
    "    print(result.context_data[\"claims\"].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This function takes a list of user queries and generates the next candidate questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "question_generator = LocalQuestionGen(\n",
    "    llm=llm,\n",
    "    context_builder=context_builder,\n",
    "    token_encoder=token_encoder,\n",
    "    llm_params=llm_params,\n",
    "    context_builder_params=local_context_params,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages {'role': 'system', 'content': '\\n---Role---\\n\\nYou are a helpful assistant generating a bulleted list of 5 questions about data in the tables provided.\\n\\n\\n---Data tables---\\n\\n-----Conversation History-----\\nturn|content\\nuser|Tell me about Agent Mercer\\n\\n\\n-----Reports-----\\nid|title|content\\n1|Graph RAG Community|\"# Graph RAG Community\\n\\nThe Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\\n\\n## Graph RAG is a graph-based approach to question answering\\n\\nThe Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\\n\\n## Model training is a crucial aspect of the Graph RAG community\\n\\nModel training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Evaluation metrics are essential for assessing the performance of question answering models\\n\\nThe Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\\n\\n## Graph RAG is implemented in Python\\n\\nThe Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Graph RAG has a strong focus on Microsoft\\n\\nThe Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company\\'s resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\\n\\n\\n-----Entities-----\\nid|entity|description|number of relationships\\n19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\\n4|TEXT DATA|A dataset of text used for training and testing question answering models|2\\n18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\\n1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\\n24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\\n17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\\n15|INDEXING||1\\n12|TEXT||1\\n5|MODEL TRAINING|A process of training machine learning models on a dataset|2\\n2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\\n21|TEXT PROCESSING|The process of extracting information from text documents|1\\n8|MS|Microsoft is the company behind the Graph RAG implementation|1\\n23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\\n13|METHODS||1\\n0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\\n7|HTTPS://AKA.MS/GRAPHRAG||1\\n16|SEARCHING||1\\n6|EVALUATION METRICS|A set of metrics used to evaluate the performance of question answering models|2\\n14|SYSTEMS||1\\n20|LLM||5\\n\\n\\n-----Relationships-----\\nid|source|target|description|weight|rank|links\\n1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|3\\n23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|4\\n2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|3\\n3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|3\\n4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|1\\n20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|4\\n26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|4\\n27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|4\\n6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|1\\n22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|1\\n21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|1\\n24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\\n0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|8\\n5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|8\\n7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|8\\n8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|8\\n9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|8\\n10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|8\\n11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|8\\n13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|8\\n17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|3\\n18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|3\\n19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|3\\n15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|2\\n16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|2\\n25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|1\\n\\n\\n-----Sources-----\\nid|text\\n6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\\n0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\\n4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\\n2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\\n\\n\\n\\n---Goal---\\n\\nGiven a series of example questions provided by the user, generate a bulleted list of 5 candidates for the next question. Use - marks as bullet points.\\n\\nThese candidate questions should represent the most important or urgent information content or themes in the data tables.\\n\\nThe candidate questions should be answerable using the data tables provided, but should not mention any specific data fields or data tables in the question text.\\n\\nIf the user\\'s questions reference several named entities, then each candidate question should reference all named entities.\\n\\n---Example questions---\\n'}\n",
      "input \n",
      "---Role---\n",
      "\n",
      "You are a helpful assistant generating a bulleted list of 5 questions about data in the tables provided.\n",
      "\n",
      "\n",
      "---Data tables---\n",
      "\n",
      "-----Conversation History-----\n",
      "turn|content\n",
      "user|Tell me about Agent Mercer\n",
      "\n",
      "\n",
      "-----Reports-----\n",
      "id|title|content\n",
      "1|Graph RAG Community|\"# Graph RAG Community\n",
      "\n",
      "The Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\n",
      "\n",
      "## Graph RAG is a graph-based approach to question answering\n",
      "\n",
      "The Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\n",
      "\n",
      "## Model training is a crucial aspect of the Graph RAG community\n",
      "\n",
      "Model training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\n",
      "\n",
      "## Evaluation metrics are essential for assessing the performance of question answering models\n",
      "\n",
      "The Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\n",
      "\n",
      "## Graph RAG is implemented in Python\n",
      "\n",
      "The Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\n",
      "\n",
      "## Graph RAG has a strong focus on Microsoft\n",
      "\n",
      "The Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company's resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\n",
      "\n",
      "\n",
      "-----Entities-----\n",
      "id|entity|description|number of relationships\n",
      "19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\n",
      "4|TEXT DATA|A dataset of text used for training and testing question answering models|2\n",
      "18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\n",
      "1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\n",
      "24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\n",
      "17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\n",
      "15|INDEXING||1\n",
      "12|TEXT||1\n",
      "5|MODEL TRAINING|A process of training machine learning models on a dataset|2\n",
      "2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\n",
      "21|TEXT PROCESSING|The process of extracting information from text documents|1\n",
      "8|MS|Microsoft is the company behind the Graph RAG implementation|1\n",
      "23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\n",
      "13|METHODS||1\n",
      "0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\n",
      "7|HTTPS://AKA.MS/GRAPHRAG||1\n",
      "16|SEARCHING||1\n",
      "6|EVALUATION METRICS|A set of metrics used to evaluate the performance of question answering models|2\n",
      "14|SYSTEMS||1\n",
      "20|LLM||5\n",
      "\n",
      "\n",
      "-----Relationships-----\n",
      "id|source|target|description|weight|rank|links\n",
      "1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|3\n",
      "23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|4\n",
      "2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|3\n",
      "3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|3\n",
      "4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|1\n",
      "20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|4\n",
      "26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|4\n",
      "27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|4\n",
      "6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|1\n",
      "22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|1\n",
      "21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|1\n",
      "24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\n",
      "0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|8\n",
      "5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|8\n",
      "7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|8\n",
      "8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|8\n",
      "9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|8\n",
      "10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|8\n",
      "11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|8\n",
      "13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|8\n",
      "17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|3\n",
      "18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|3\n",
      "19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|3\n",
      "15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|2\n",
      "16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|2\n",
      "25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|1\n",
      "\n",
      "\n",
      "-----Sources-----\n",
      "id|text\n",
      "6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\n",
      "0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\n",
      "4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\n",
      "2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\n",
      "\n",
      "\n",
      "\n",
      "---Goal---\n",
      "\n",
      "Given a series of example questions provided by the user, generate a bulleted list of 5 candidates for the next question. Use - marks as bullet points.\n",
      "\n",
      "These candidate questions should represent the most important or urgent information content or themes in the data tables.\n",
      "\n",
      "The candidate questions should be answerable using the data tables provided, but should not mention any specific data fields or data tables in the question text.\n",
      "\n",
      "If the user's questions reference several named entities, then each candidate question should reference all named entities.\n",
      "\n",
      "---Example questions---\n",
      "\n",
      "payload {'messages': [{'content': '\\n---Role---\\n\\nYou are a helpful assistant generating a bulleted list of 5 questions about data in the tables provided.\\n\\n\\n---Data tables---\\n\\n-----Conversation History-----\\nturn|content\\nuser|Tell me about Agent Mercer\\n\\n\\n-----Reports-----\\nid|title|content\\n1|Graph RAG Community|\"# Graph RAG Community\\n\\nThe Graph RAG community revolves around a graph-based approach to question answering, model training, and evaluation metrics. It involves various entities such as GRAPH RAG, QUESTION ANSWERING, MODEL TRAINING, EVALUATION METRICS, TEXT DATA, and more.\\n\\n## Graph RAG is a graph-based approach to question answering\\n\\nThe Graph RAG community centers around a graph-based approach to question answering [Data: Entities (3, 6); Relationships (0)]. This approach uses a set of evaluation metrics to evaluate the performance of question answering models. The Graph RAG approach is trained on a large corpus of text data and can be accessed at a specific URL [Data: Entities (7, 11); Relationships (11)]. This graph-based approach has several advantages over traditional methods, including improved scalability and flexibility [Data: Relationships (0)]. However, it also requires significant computational resources and expertise in natural language processing [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on improving the performance of this approach through various research initiatives and collaborations [Data: Relationships (10, 13)].\\n\\n## Model training is a crucial aspect of the Graph RAG community\\n\\nModel training is a critical component of the Graph RAG community, as it enables the development of accurate question answering models [Data: Entities (5); Relationships (9)]. The Graph RAG approach uses a model training process to train its models on a large corpus of text data [Data: Entities (8); Relationships (8)]. The Graph RAG community has developed various techniques and tools for efficient model training, including the use of private text corpora and evaluation metrics [Data: Entities (4, 6); Relationships (5, 10)]. However, model training also requires significant computational resources and expertise in machine learning [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the efficiency and accuracy of its model training process through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Evaluation metrics are essential for assessing the performance of question answering models\\n\\nThe Graph RAG community uses a set of evaluation metrics to assess the performance of its question answering models [Data: Entities (6); Relationships (10)]. These metrics include precision, recall, and F1 score, which provide a comprehensive understanding of model performance [Data: Entities (4); Relationships (4)]. The Graph RAG approach is evaluated using these metrics, which helps identify areas for improvement and optimize the model training process [Data: Entities (8); Relationships (10)]. However, the choice of evaluation metric can significantly impact the results, and the Graph RAG community is actively working on developing more accurate and robust metrics [Data: Relationships (13)]. The use of evaluation metrics has several advantages over traditional methods, including improved transparency and accountability [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in natural language processing and machine learning [Data: Entities (9); Relationships (5)].\\n\\n## Graph RAG is implemented in Python\\n\\nThe Graph RAG community has developed a Python implementation of its graph-based approach to question answering [Data: Entities (12); Relationships (12)]. This implementation provides a flexible and efficient way to develop and train question answering models [Data: Entities (5); Relationships (9)]. The Python implementation is widely used within the Graph RAG community, as it enables researchers and developers to easily integrate the Graph RAG approach into their existing workflows [Data: Entities (4); Relationships (5)]. However, it also requires significant expertise in programming languages and natural language processing [Data: Entities (9); Relationships (5)]. The Graph RAG community is actively working on improving the Python implementation through various research initiatives and collaborations [Data: Relationships (13)].\\n\\n## Graph RAG has a strong focus on Microsoft\\n\\nThe Graph RAG community has a strong focus on Microsoft, as it is the company behind the Graph RAG implementation [Data: Entities (8); Relationships (13)]. This focus is reflected in the use of Microsoft-specific tools and technologies within the Graph RAG approach [Data: Entities (4); Relationships (5)]. The Graph RAG community has developed a close relationship with Microsoft, which enables it to leverage the company\\'s resources and expertise [Data: Entities (8); Relationships (13)]. However, this focus also raises concerns about the potential for bias and conflict of interest within the Graph RAG community [Data: Entities (4); Relationships (5)]. The Graph RAG community is actively working on addressing these concerns through various research initiatives and collaborations [Data: Relationships (13)].\"\\n\\n\\n-----Entities-----\\nid|entity|description|number of relationships\\n19|COMMUNITY SUMMARIES|Pre-generated summaries for groups of closely-related entities|2\\n4|TEXT DATA|A dataset of text used for training and testing question answering models|2\\n18|SOURCE DOCUMENTS|The original texts that are being processed to build the entity knowledge graph|3\\n1|PRIVATE TEXT CORPORA|A collection of text that is not publicly available|3\\n24|ENTITY EXTRACTION ALGORITHM|A algorithm for extracting entities from text documents|1\\n17|GRAPH-BASED TEXT INDEX|A graph-based index of entities and relationships derived from source documents|2\\n15|INDEXING||1\\n12|TEXT||1\\n5|MODEL TRAINING|A process of training machine learning models on a dataset|2\\n2|USER QUESTIONS|Questions asked by users to be answered by the Graph RAG approach|2\\n21|TEXT PROCESSING|The process of extracting information from text documents|1\\n8|MS|Microsoft is the company behind the Graph RAG implementation|1\\n23|DOCUMENT ANALYSIS TOOL|A tool for analyzing and extracting information from text documents|1\\n13|METHODS||1\\n0|QUESTION ANSWERING|A method of using a graph to answer questions based on text|5\\n7|HTTPS://AKA.MS/GRAPHRAG||1\\n16|SEARCHING||1\\n6|EVALUATION METRICS|A set of metrics used to evaluate the performance of question answering models|2\\n14|SYSTEMS||1\\n20|LLM||5\\n\\n\\n-----Relationships-----\\nid|source|target|description|weight|rank|links\\n1|QUESTION ANSWERING|PRIVATE TEXT CORPORA|Question answering is used to index private text corpora using the Graph RAG approach|4.0|8|3\\n23|SOURCE DOCUMENTS|LLM|The LLM is used to derive an entity knowledge graph from the source documents|16.0|8|4\\n2|QUESTION ANSWERING|TEXT DATA|Question answering models are trained on a large corpus of text data using the Graph RAG approach|3.0|7|3\\n3|QUESTION ANSWERING|MODEL TRAINING|Question answering models are trained using the Graph RAG approach and a model training process|2.0|7|3\\n4|QUESTION ANSWERING|EVALUATION METRICS|Question answering models are evaluated using the Graph RAG approach and a set of evaluation metrics|2.0|7|1\\n20|GRAPH-BASED TEXT INDEX|LLM|The LLM is used to build a graph-based text index in two stages|16.0|7|4\\n26|LLM|DOCUMENT ANALYSIS TOOL|The LLM is used in conjunction with a document analysis tool to extract entities and relationships|8.0|6|4\\n27|LLM|ENTITY EXTRACTION ALGORITHM|The LLM is used in conjunction with an entity extraction algorithm to extract entities and relationships|1.0|6|4\\n6|PRIVATE TEXT CORPORA|USER QUESTIONS|User questions are answered by indexing private text corpora using the Graph RAG approach|3.0|5|1\\n22|SOURCE DOCUMENTS|COMMUNITY SUMMARIES|Community summaries are pre-generated for all groups of closely-related entities from source documents|10.0|5|1\\n21|GRAPH-BASED TEXT INDEX|COMMUNITY SUMMARIES|The graph-based text index is used to pre-generate community summaries for all groups of closely-related entities|2.0|4|1\\n24|SOURCE DOCUMENTS|TEXT PROCESSING|Source documents are processed using various techniques|5.0|4|1\\n0|QUESTION ANSWERING|GRAPH RAG|The Graph RAG approach uses question answering as a method to answer user questions|16.0|14|8\\n5|PRIVATE TEXT CORPORA|GRAPH RAG|The Graph RAG approach is used to index private text corpora|10.0|12|8\\n7|USER QUESTIONS|GRAPH RAG|The Graph RAG approach scales with the generality of user questions|6.0|11|8\\n8|GRAPH RAG|TEXT DATA|The Graph RAG approach is trained on a large corpus of text data|4.0|11|8\\n9|GRAPH RAG|MODEL TRAINING|The Graph RAG approach is trained using a model training process|2.0|11|8\\n10|GRAPH RAG|EVALUATION METRICS|The Graph RAG approach is evaluated using a set of evaluation metrics|2.0|11|8\\n11|GRAPH RAG|HTTPS://AKA.MS/GRAPHRAG|Graph RAG can be accessed at this URL|2.0|10|8\\n13|GRAPH RAG|MS|Graph RAG is a Microsoft implementation|1.0|10|8\\n17|RAG SYSTEMS|TEXT|RAG Systems index large amounts of text|1.0|5|3\\n18|RAG SYSTEMS|SYSTEMS|RAG Systems are a type of search engine system|1.0|5|3\\n19|RAG SYSTEMS|INDEXING|RAG Systems index large amounts of text|1.0|5|3\\n15|QFS|METHODS|QFS refers to a method for querying and searching large amounts of text|1.0|4|2\\n16|QFS|SEARCHING|QFS methods fail to scale to the quantities of text indexed by typical RAG systems, which makes searching difficult|1.0|4|2\\n25|LLM|ENTITY KNOWLEDGE GRAPH|The LLM is used to build the entity knowledge graph|8.0|6|1\\n\\n\\n-----Sources-----\\nid|text\\n6|Our approach uses an LLM to build a graph-based text index in two stages: first to derive an entity knowledge graph from the source documents, then to pre-generate community summaries for all groups of closely-related entities.\\n0|To combine the strengths of these contrasting methods, we propose a Graph RAG approach to question answering over private text corpora that scales with both the generality of user questions and the quantity of source text to be indexed.\\n4|Prior QFS methods, meanwhile, fail to scale to the quantities of text indexed by typical RAG systems.\\n2|An open-source, Python-based implementation of both global and local Graph RAG approaches is forthcoming at https://aka.ms/graphrag.\\n\\n\\n\\n---Goal---\\n\\nGiven a series of example questions provided by the user, generate a bulleted list of 5 candidates for the next question. Use - marks as bullet points.\\n\\nThese candidate questions should represent the most important or urgent information content or themes in the data tables.\\n\\nThe candidate questions should be answerable using the data tables provided, but should not mention any specific data fields or data tables in the question text.\\n\\nIf the user\\'s questions reference several named entities, then each candidate question should reference all named entities.\\n\\n---Example questions---\\n', 'role': 'user'}], 'model': 'llama3.1', 'stream': False, 'n': 1, 'temperature': 0.0, 'streaming': True, 'max_tokens': 2000}\n",
      "messages {'role': 'user', 'content': 'What happens in Dulce military base?'}\n",
      "input What happens in Dulce military base?\n",
      "payload {'messages': [{'content': 'What happens in Dulce military base?', 'role': 'user'}], 'model': 'llama3.1', 'stream': False, 'n': 1, 'temperature': 0.0, 'streaming': True, 'max_tokens': 2000}\n",
      "response generations=[[ChatGeneration(text='Based on the provided data tables and goal, here are five candidate questions that represent important or urgent information content or themes:\\n\\n- How does the Graph RAG approach scale with the generality of user questions?\\n- What techniques are used to process source documents in the Graph RAG system?\\n- Can the Graph RAG approach be trained on a large corpus of text data?\\n- How is the Graph RAG approach evaluated using a set of evaluation metrics?\\n- What is the relationship between the Graph RAG approach and question answering over private text corpora?\\n\\nThese candidate questions are answerable using the provided data tables, but do not mention any specific data fields or data tables in the question text. They also reference all named entities mentioned in the example questions.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='Based on the provided data tables and goal, here are five candidate questions that represent important or urgent information content or themes:\\n\\n- How does the Graph RAG approach scale with the generality of user questions?\\n- What techniques are used to process source documents in the Graph RAG system?\\n- Can the Graph RAG approach be trained on a large corpus of text data?\\n- How is the Graph RAG approach evaluated using a set of evaluation metrics?\\n- What is the relationship between the Graph RAG approach and question answering over private text corpora?\\n\\nThese candidate questions are answerable using the provided data tables, but do not mention any specific data fields or data tables in the question text. They also reference all named entities mentioned in the example questions.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 151, 'prompt_tokens': 1026, 'total_tokens': 1177, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-a1cb11e0-42ab-450d-8825-04e06ce0310a-0', usage_metadata={'input_tokens': 1026, 'output_tokens': 151, 'total_tokens': 1177}))], [ChatGeneration(text='The infamous Dulce Base. There are many conspiracy theories surrounding this topic, and I\\'ll provide an overview of the claims while also separating fact from fiction.\\n\\n**Location:** The alleged Dulce Base is said to be located near the town of Dulce, New Mexico, USA. This area is known for its high desert terrain and has been associated with various UFO sightings over the years.\\n\\n**Conspiracy theories:**\\n\\n1. **Alien base:** One of the most popular conspiracy theories claims that Dulce Base is an underground alien research facility where extraterrestrial beings are being studied by the US government.\\n2. **Reptilian humanoids:** Some believe that the aliens at Dulce Base are reptilian humanoids, also known as \"Grays,\" which have been described in various UFO abduction cases.\\n3. **Secret experiments:** Another theory suggests that the base is used for secret experiments on humans and animals, including mind control and genetic manipulation.\\n4. **Government cover-up:** Many believe that the US government has been covering up the existence of Dulce Base to avoid public panic.\\n\\n**Debunking:**\\n\\n1. **No credible evidence:** Despite numerous claims, there is no concrete evidence to support the existence of an alien base at Dulce or any other location.\\n2. **US Air Force presence:** The US Air Force has a facility near Dulce, known as the Albuquerque Air Route Traffic Control Center (ARTCC), which is responsible for air traffic control in the region. However, this facility is not associated with any secret alien research programs.\\n3. **Local legends and folklore:** Many of the stories surrounding Dulce Base are based on local legends and folklore, which have been exaggerated or distorted over time.\\n\\n**The \"Dulce Book\" controversy:**\\n\\nIn 1994, a book titled \"Dulce: A History of a UFO Incident\" was published by Brinsley Leppington. The book claimed to reveal the existence of an alien base at Dulce and provided detailed descriptions of alleged underground tunnels and facilities. However, many experts have questioned the credibility of this book, citing inconsistencies and lack of evidence.\\n\\n**Conclusion:**\\n\\nWhile there are many conspiracy theories surrounding Dulce Base, there is no concrete evidence to support the claims of an alien research facility or secret government experiments. The stories surrounding this topic are largely based on local legends, folklore, and speculation.', generation_info={'finish_reason': 'stop', 'logprobs': None}, message=AIMessage(content='The infamous Dulce Base. There are many conspiracy theories surrounding this topic, and I\\'ll provide an overview of the claims while also separating fact from fiction.\\n\\n**Location:** The alleged Dulce Base is said to be located near the town of Dulce, New Mexico, USA. This area is known for its high desert terrain and has been associated with various UFO sightings over the years.\\n\\n**Conspiracy theories:**\\n\\n1. **Alien base:** One of the most popular conspiracy theories claims that Dulce Base is an underground alien research facility where extraterrestrial beings are being studied by the US government.\\n2. **Reptilian humanoids:** Some believe that the aliens at Dulce Base are reptilian humanoids, also known as \"Grays,\" which have been described in various UFO abduction cases.\\n3. **Secret experiments:** Another theory suggests that the base is used for secret experiments on humans and animals, including mind control and genetic manipulation.\\n4. **Government cover-up:** Many believe that the US government has been covering up the existence of Dulce Base to avoid public panic.\\n\\n**Debunking:**\\n\\n1. **No credible evidence:** Despite numerous claims, there is no concrete evidence to support the existence of an alien base at Dulce or any other location.\\n2. **US Air Force presence:** The US Air Force has a facility near Dulce, known as the Albuquerque Air Route Traffic Control Center (ARTCC), which is responsible for air traffic control in the region. However, this facility is not associated with any secret alien research programs.\\n3. **Local legends and folklore:** Many of the stories surrounding Dulce Base are based on local legends and folklore, which have been exaggerated or distorted over time.\\n\\n**The \"Dulce Book\" controversy:**\\n\\nIn 1994, a book titled \"Dulce: A History of a UFO Incident\" was published by Brinsley Leppington. The book claimed to reveal the existence of an alien base at Dulce and provided detailed descriptions of alleged underground tunnels and facilities. However, many experts have questioned the credibility of this book, citing inconsistencies and lack of evidence.\\n\\n**Conclusion:**\\n\\nWhile there are many conspiracy theories surrounding Dulce Base, there is no concrete evidence to support the claims of an alien research facility or secret government experiments. The stories surrounding this topic are largely based on local legends, folklore, and speculation.', additional_kwargs={'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 485, 'prompt_tokens': 18, 'total_tokens': 503, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama', 'finish_reason': 'stop', 'logprobs': None}, id='run-6fd564d4-32d3-4a95-ba68-301241766370-0', usage_metadata={'input_tokens': 18, 'output_tokens': 485, 'total_tokens': 503}))]] llm_output={'token_usage': {'completion_tokens': 636, 'prompt_tokens': 1044, 'total_tokens': 1680, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama'} run=[RunInfo(run_id=UUID('a1cb11e0-42ab-450d-8825-04e06ce0310a')), RunInfo(run_id=UUID('6fd564d4-32d3-4a95-ba68-301241766370'))] type='LLMResult'\n",
      "response.llm_output {'token_usage': {'completion_tokens': 636, 'prompt_tokens': 1044, 'total_tokens': 1680, 'completion_tokens_details': None}, 'model_name': 'llama3.1', 'system_fingerprint': 'fp_ollama'}\n",
      "generation_texts ['Based on the provided data tables and goal, here are five candidate questions that represent important or urgent information content or themes:\\n\\n- How does the Graph RAG approach scale with the generality of user questions?\\n- What techniques are used to process source documents in the Graph RAG system?\\n- Can the Graph RAG approach be trained on a large corpus of text data?\\n- How is the Graph RAG approach evaluated using a set of evaluation metrics?\\n- What is the relationship between the Graph RAG approach and question answering over private text corpora?\\n\\nThese candidate questions are answerable using the provided data tables, but do not mention any specific data fields or data tables in the question text. They also reference all named entities mentioned in the example questions.']\n",
      "['Based on the provided data tables and goal, here are five candidate questions that represent important or urgent information content or themes:\\n\\n- How does the Graph RAG approach scale with the generality of user questions?\\n- What techniques are used to process source documents in the Graph RAG system?\\n- Can the Graph RAG approach be trained on a large corpus of text data?\\n- How is the Graph RAG approach evaluated using a set of evaluation metrics?\\n- What is the relationship between the Graph RAG approach and question answering over private text corpora?\\n\\nThese candidate questions are answerable using the provided data tables, but do not mention any specific data fields or data tables in the question text. They also reference all named entities mentioned in the example questions.']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/luwi/Documents/Code/microsoft_graphrag_local/custom_graphrag_venv/lib/python3.11/site-packages/langchain_openai/chat_models/base.py:357: UserWarning: Unexpected type for token usage: <class 'NoneType'>\n",
      "  warnings.warn(f\"Unexpected type for token usage: {type(new_usage)}\")\n"
     ]
    }
   ],
   "source": [
    "\n",
    "question_history = [\n",
    "    \"Tell me about Agent Mercer\",\n",
    "    \"What happens in Dulce military base?\",\n",
    "]\n",
    "candidate_questions = await question_generator.agenerate(\n",
    "    question_history=question_history, context_data=None, question_count=5\n",
    ")\n",
    "print(candidate_questions.response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
